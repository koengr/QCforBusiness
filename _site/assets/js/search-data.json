{"0": {
    "doc": "Design showcase",
    "title": "Tables",
    "content": "| Food | Description | Category | Sample type | . | Apples | A small, somewhat round … | Fruit | Fuji | . | Bananas | A long and curved, often-yellow … | Fruit | Snow | . | Kiwis | A small, hairy-skinned sweet … | Fruit | Golden | . | Oranges | A spherical, orange-colored sweet … | Fruit | Navel | . | Priority apples | Second priority | Third priority | . | ambrosia | gala | red delicious | . | pink lady | jazz | macintosh | . | honeycrisp | granny smith | fuji | . ",
    "url": "/design-tests.html#tables",
    
    "relUrl": "/design-tests.html#tables"
  },"1": {
    "doc": "Design showcase",
    "title": "Expanding boxes / accordions",
    "content": ". | This is Accordion 1 Lorem ipsum dolor sit amet, consectetur adipiscing elit. | . | This is accordion2; you can provide the contents inline! For details, see _includes . | . Detailsbox using capture mode The first line is automatically selected to be the “summary”. \\( 3+3 = \\frac{1}{\\pi} \\) is great. Alternatively, you can directly specify content... This is detailsbox.html. It takes the 2nd line as summary header (assuming the 1st line is just ‘\\n’.) Here is more text. And math: \\( \\pi + \\frac{1}{\\cos(3)} \\). Final line. A fancy Details box depending on in-doc CSS Give me attention or face the wrath of my claws give me attention or face the wrath of my claws and pretend not to be evil cats go for world domination allways wanting food. Eat owner's food playing with balls of wool and meow and walk away, and bleghbleghvomit my furball really tie the room together. Cuddle no cuddle cuddle love scratch scratch cat. ",
    "url": "/design-tests.html#expanding-boxes--accordions",
    
    "relUrl": "/design-tests.html#expanding-boxes--accordions"
  },"2": {
    "doc": "Design showcase",
    "title": "“At a glance” header",
    "content": "TL;DR . | Show the post in a flexible way. | Show the figures any place | Show the maths, the code blocks in a beautiful way. | and many things else… | . ",
    "url": "/design-tests.html#at-a-glance-header",
    
    "relUrl": "/design-tests.html#at-a-glance-header"
  },"3": {
    "doc": "Design showcase",
    "title": "Fancy buttons",
    "content": "Standard button for GH-pages Standard button for GH-pages . Bigger button (won’t work on GH) – START READING . ",
    "url": "/design-tests.html#fancy-buttons",
    
    "relUrl": "/design-tests.html#fancy-buttons"
  },"4": {
    "doc": "Design showcase",
    "title": "Passing arguments to custom templates",
    "content": "This is a fancy box. **It gives an example** of how to pass arugments to a _include template file. I was wondering if it works with multiple lines. And maybe even [hyperlinks](google.com)? ",
    "url": "/design-tests.html#passing-arguments-to-custom-templates",
    
    "relUrl": "/design-tests.html#passing-arguments-to-custom-templates"
  },"5": {
    "doc": "Design showcase",
    "title": "Colored boxes",
    "content": "$ sudo apt-get update . See other colored boxes below. Fancy label . red label . Special highlighted text . This is a custom note title . A paragraph with a custom title callout . This is a “new” type . red label . Another paragraph . The last paragraph . ",
    "url": "/design-tests.html#colored-boxes",
    
    "relUrl": "/design-tests.html#colored-boxes"
  },"6": {
    "doc": "Design showcase",
    "title": "Design showcase",
    "content": ". | Tables | Expanding boxes / accordions | “At a glance” header | Fancy buttons | Passing arguments to custom templates | Colored boxes | . This is a gradient background part. This is a test! This is a beautiful main page. Does latex work? . \\[\\pi = \\frac{1}{2}\\] And inline it goes like \\( 3+3 = \\frac{1}{\\pi} \\) this. ",
    "url": "/design-tests.html",
    
    "relUrl": "/design-tests.html"
  },"7": {
    "doc": "Introduction to Quantum Computing for Business",
    "title": "Introduction to Quantum Computing for Business",
    "content": "Introduction to Quantum Computing for Business . This free book contains everything you should know about quantum computers, without going into tedious technical details. It answers questions such as: . | What are the applications of quantum computers and quantum networks? . | How long will it take before quantum computing becomes competetive? . | What are the consequences for cybersecurity? . | How can an organisation effectively prepare? . | What is the status of today’s hardware? . | . Start reading . Audience . This book targets anyone who encounters quantum technologies in their professional lives, but who don’t not need a full physics background. This includes: . | Managers and strategic decision makers . | Consultants . | Policy makers . | CIO or CISO departments . | Investors . | . |   | This book is about… |   |   | This book does not contain… | . | ✓ | The impact that quantum technology has on business and society |   | ✗ | Essential math or physics | . | ✓ | Opportunities and threats |   | ✗ | Quantum programming | . | ✓ | Timelines |   | ✗ | Exhaustive information about every possible detail | . | ✓ | Links to other great resources |   |   |   | . Get the softcover . Prefer to read a printed edition? A physical edition will be released in Q4 2024. ",
    "url": "/",
    
    "relUrl": "/"
  },"8": {
    "doc": "Further reading",
    "title": "Further reading",
    "content": "I want to learn the technical details . For (late) high school students: . (or those who followed high-school level mathematics): . | Quantum Quest [EN] (intensive 5-week online course about theory of quantum computing. Materials freely available for self-study).  . | Quantum Rules [NL] (1-day lab experiments dealing with quantum physics) . | Masterclass Quantum [NL] (3-day extracurricular course about the theory of quantum computing and particle physics) . | . Undergraduate (Bachelor's) university level: . | Quantum.Country [Website] – the “Duolingo of Quantum Computing”, a very well-written introduction for those with late high-school or early university level math background.  . | Quantum Computation and Quantum Information (Nielsen, Chuang) [Book] – the “bible of quantum computing”. Perhaps not the most up-to-date, but definitely the most well-known resource in our field. Sets the standards for jargon and notation.  . | . | Quantum Computer Science: An Introduction (Mermin) [Book] – a well-written introduction, with quite some focus on manipulating quantum circuits. | Quantum Computing Since Democritus (Aaronson) [Book] – Aaronson is an authority in the field. His book touched upon many topics such as the foundations of computer science, black holes and consciousness, making it a good read for those looking for something much more broad than just quantum computing. | . Graduate (Master's) level: . These assume no prior knowledge, but require a strong background in mathematics (i.e. Linear Algebra, Calculus, advanced inequality bounds and approximations, etc.). In exchange, they go into much more detail.  . | Lecture Notes for UvA course “Quantum Computing” by Ronald de Wolf, which is frequently updated and features some cutting-edge algorithms. Via the course website, you can find the link and password to view all the recorded lectures too.  | . | Lecture Notes for Caltech course “Quantum Computing” by John Preskil  | .   . For research projects, internships or theses: . | Internships offered at Centrum Wiskunde en Informatica . | Quantum Delta NL hosts a job board.  . | Students of University of Amsterdam can find quantum projects on Datanose.   . | . Scientific papers . Introductions mostly aimed at (non-quantum) scientists. All papers we mention are open-access and peer-reviewed, which guarantees a correct and balanced presentation (and makes them suitable for you to cite).  . | Quantum algorithms: an overview (Ashley Montanaro) . | The Potential Impact of Quantum Computers on Society (Ronald de Wolf) [video lecture] . | . Scientific opinions and discussions . | Scott Aaronson’s blog. Although written from a theoretical computer science perspective, this blog addresses a very broad range of quantum computing topics. Prof. Aaronson has a strong authority in the field, and his posts attract readership and comments from a broad range of prominent scientists.  | . Scientific news . None of these focus exclusively on Quantum Technology, but all offer high-quality news (and surely none would miss any important quantum breakthroughs).  . | Quanta Magazine . | Phys.org . | Quantum Universe [NL] . | . I want to learn to program a quantum computer . There are several programming packages for quantum computers, mostly maintained by major hardware providers. Nearly all of these offer great introductory tutorials that guide your through both the basics of Quantum Computing and the usage of the package.  . The ones we recommend below are all in Python:  . | Qiskit: Introduction to Quantum Computing (by IBM) . | Cirq tutorials (by Google)  . | QWorld Bronze offers various online training programs around the world, mostly focused on Qiskit and sometimes ProjectQ. | . I want to learn more about business opportunities . Business News Websites . | The Quantum Observer – newly formed news collection platform, allowing upvotes and comments to news articles.  | . | Quantum Computing Report – don’t be fooled by the basic look on the website. The content is written with a very critical eye and with very relevant contextual information.  | . | The Quantum Insider | . Overview articles about business opportunities (close to this blog) . Of course, we first recommend that you start reading our Professional’s Guide to Quantum Computing!  . Many others have written similar guides. Most of these come from consultants of hardware providers who have a financial interest in making others get started with quantum. In our opinion, the articles are sometimes too optimistic and predict that quantum applications will come much sooner than the typical expert would anticipate. On the other hand, they collect insightful details about financial matters.  . | Deloitte – A business leader’s guide to quantum technology | . | McKinsey – A game plan for quantum computing  | . | BCG – The Next Decade in Quantum Computing—and How to Play | . Workshops . | The Workshop General Awareness Quantum Computing is an introduction to business opportunties that requires no deep mathemtical background, but gives an essential overview to how quantum computers will impact businesses and governments.  | . Major conferences . | Q2B (organized by QCWare) . | IQT (Inside Quantum Technology) . | Quantum.Tech (organized by Alpha Events)s . | . ",
    "url": "/section_13.html",
    
    "relUrl": "/section_13.html"
  },"9": {
    "doc": "1 Preface, Why this book?",
    "title": "Preface: Why this book?",
    "content": ". “Quantum computing will change everything,” the man in front of me said. Standing tall and confident, he took another sip of his drink before continuing, “It will be the biggest revolution since the invention of the transistor. Imagine a world where we can cure any disease with personalised medicine. A world where new energy sources will free us from our dependence on fossil fuels. Not to mention that…” . “Well—” I tried to interrupt, but the man passionately rattled on. “It will finally enable us to build general Artificial Intelligence that can take over our tedious everyday jobs, so 95% of our population no longer has to work!” . “You know that quantum computers are still quite some years away, right?”, I countered. He leaned in, eyes still gleaming with excitement. “That’s what most people think. But the reality is, we’re closer than ever. Quantum supremacy has already been achieved. Google did it in 2019. Since then, progress has been exponential. Did you see the presentation by that guy from Goldman Sachs? Their investments see higher returns than ever since their new Monte Carlo algorithm.” . The above conversation captures a feeling that many seasoned experts in quantum computing will have. And this is by no means exaggerated. Plentiful reputable sources report that ‘quantum’ is key in tackling climate change, revolutionising AI, and building unhackable networks. Experts who are actually building these quantum computers are much, much more reluctant. At an academic conference, you hear a completely different story. Scientists ridicule the absurd claims that come from consultants and some aggressive startups. They will point out that the applications of quantum computers are still very much uncertain, and that we’re still searching for convincing uses of these computers. The quantum scene seems to have two completely separate worlds. A business world, that reaches out to anybody who will hear them about the unprecedented capabilities of quantum computers. And the academic world, the community of experts that quietly bring this quantum computer to reality, sharing their results in technical papers that require a PhD to understand. I was grasped by this paradoxical situation. What can we really expect from quantum technology? How powerful are quantum computers really, and how does this compare to other promising technologies? In what year will we have a large-scale quantum computer, and what will it look like? These are billion-dollar questions, but the answers will wildly vary, depending on who you ask. After searching for these answers for over a decade, I acquired a unique position. I’ve become a native in both the academic and the commercial world. I’ve seen all the arguments from both sides and can cut through dishonest and deceptive claims. I have the privilege of being surrounded by the world’s most renowned experts from both worlds, and I have heard their unsalted opinions and predictions that they would never dare to publicly announce. And most of all, after training many new colleagues and setting up professional learning programs, I developed a good intuition about what newcomers want to know about quantum technology, and how to explain it in an accessible way. I started writing these texts for two reasons. First, I aim to offer an alternative to the hyped and unbalanced articles that would otherwise populate the top entries in Google search results (or even the New York Times best-selling books). Second, I see the need for a reliable source of information that others can reference when disagreeing about facts or debunking myths. I am already very grateful for the many colleagues who frequently refer to an early version of this book! . That doesn’t mean that this book contains only confirmed facts – not at all! Writing about a computer of the future comes with uncertainty. In 2005, nobody could have predicted that just a few years later, everyone would be playing games and consuming the internet on their smartphones. In 2015, nobody could have predicted the impact of Large Language Models like ChatGPT. And indeed, today, our best predictions of a future quantum revolution won’t be quite so accurate either. Even worse, experts wildly disagree in several cases. For example, the usefulness of quantum AI and optimization is continuously disputed, and the rate at which hardware will progress depends on some yet-to-discover breakthroughs. The best I could do is describe various perspectives on these matters and highlight the best arguments from either side. Without plentiful discussions and disagreements, I wouldn’t have been able to gather the facts and opinions in this book. And it shouldn’t stop there. I keep welcoming criticism, opinions, and feedback about these complex topics, hoping to refine these texts even more in future updates. Even though much is still uncertain, I think that a reliable indication of the prospects of quantum computing is more important than ever. Quantum startups are acquiring huge investments, allowing them to hire managers, software developers, salesmen, and marketers. Governments need informed policymakers, and journalists should cover quantum breakthroughs. Pretty much every organisation that deals with IT will want to keep a close eye on the impact that ‘quantum’ will have on them. This book is for precisely these people who don’t need to understand all the technical details but still need to talk, read, and write about quantum technologies. This is why I will focus on an accessible language everyone can understand. We don’t care so much about the underlying math or physics, but rather about the functionality of a quantum computer: the opportunities, the threats, and the concrete actions organisations can take. ",
    "url": "/part1/chapter_1/#preface-why-this-book",
    
    "relUrl": "/part1/chapter_1/#preface-why-this-book"
  },"10": {
    "doc": "1 Preface, Why this book?",
    "title": "1 Preface, Why this book?",
    "content": " ",
    "url": "/part1/chapter_1/",
    
    "relUrl": "/part1/chapter_1/"
  },"11": {
    "doc": "2 An introduction to the quantum world",
    "title": "An introduction to the quantum world",
    "content": "At a glance You don’t need to understand quantum mechanics to understand the functionality of quantum computers. But if you insist: quantum mechanics describes the behaviour of the smallest particles. It leads to many counter-intuitive phenomena: computer memory can store multiple pieces of data at the same time, but upon measurement, nature selects just a single piece (and throws away all the others). If you want to drive a car, do you need to understand how its engine works? Of course you don’t! In a similar vein, you don’t need to know the details of quantum physics to read the rest of this book. So feel free to skip this chapter. Nevertheless, I know that most people want to have some conceptual intuition about what quantum mechanics really is. It is not natural to leave one of the most used word in this book as an abstract concept, and it might be hard for the human brain to proceed without at least seeing some examples. Here is my best attempt to explain quantum mechanics in accessible terms. Proceed with caution, as things will surely get confusing from here. What is quantum?   . Quantum physics or quantum mechanics is the theory that describes the tiniest particles, like electrons, atoms, and sometimes even small molecules. They are the laws of nature that dictate cause and effect at the scale of nanometers. You may contrast it to Newton’s classical physics, which works great for objects the size of a building or football but becomes inaccurate at much smaller scales. Quantum is, in a sense, a refinement of classical physics: the theories are effectively identical when applied to a coffee mug, but one requires the more difficult quantum theory to describe very small things.  . Some examples of systems where quantum could play a role are: . | Atoms and the electrons that orbit around them. | Flows of electricity in microscopic (nano-scale) wires and chips . | Photons, the particles out of which ‘light’ is made. | . First, we need some physics jargon. The state of the world is a complete description of everything there is to know about its contents: all the particles inside it, their velocities, how much they rotate, etcetera. Usually, the entire universe is too big to study, so we often simplify our ‘world’ to just a single isolated particle, or to a limited piece of computer memory. For example, for our prototypical particle, we imagine we’re only interested in its location, which we’ll call $x$ (and we forget about any other structure in the world). In the spirit of computing, we might look at a ‘bit’ that stores information. You may think of it as a tiny magnet that can either point ‘up’ (0) or ‘down’ (1). Note that a state is valid for just one instant, as there could be reasons for it to change as time flows. Four surprising phenomena in the quantum world . The most iconic quantum phenomenon is superposition. Think about any property that we can (classically) measure, such as the position of a particle, or the value of a bit on a hard drive (0 or 1). In quantum mechanics, the state of the world can be such that several conflicting measurement outcomes are ‘true’ at the same time: a particle can be at multiple positions at once, or a bit could be 0 and 1 simultaneously. How can you possibly describe a state like that? Well, if we look at just a single particle, the state should contain a long list of all possible positions: to what extent is it at position x=0, to what extent at position x=1, and so forth, for every possible location that the particle can be at. And indeed, this list could be infinite! . For the case of a bit, we’d need just two numbers denoting the extent to which it is ‘0’ or ‘1’. To make things even more confusing, these numbers can be negative (and for math experts, they can even be complex numbers). Because we will talk about quantum-mechanical bits a lot, we will give them a shorter name: qubits. If we have a bunch of qubits together, we’ll call it a quantum memory. To throw in some more examples, an electron can move at a velocity of 10 m/s and 100 m/s at the same time (which obviously also leads to a superposition in its position). More relevant for us: a quantum memory might use binary notation to store numbers 5 and 11 simultanously, or even 46 different Microsoft Excel spreadsheets at once. More physics-oriented books might call this the particle-wave duality: all particles can also be described as a ‘wave’, which is yet another description of how a particle is spread out over space. The wave is high when a particle is very likely to be there, and small at unlikely locations. The second weird phenomenon is how quantum measurements work. Why do we never observe an electron at two places at the same time? Why do I never find my chair both moving and standing still? In quantum mechanics, as soon as we measure the location of a particle, it instantly jumps to just a single location at random. When we measure a qubit, it jumps to either ‘0’ or ‘1’ with some probability. When we measure the data in a quantum memory, we may find any one of the 46 spreadsheets that were stored. This means that the world is intrinsically random (and hence, not deterministic!). But this doesn’t imply that we cannot understand it. We can calculate the probabilities of measurement outcomes with incredible precision as long as we know the state before the measurement. It is important to note that we cannot learn anything about the world without measuring – it is our only way to obtain data from the world, and any process that extracts data must involve a measurement. However, measurements are destructive in the sense that they change the state of the world. In fact, they delete all the rich data encoded in a superposition! If a particle was initially at position x=0, x=3 and x=10, all simultaneously, then upon measurement, it jumps to one of these three options. In jargon, we call this instantaneous change a ‘collapse’. From then onwards, it is 100% at a fixed location: if we measure x=3, then from then onwards, it is located uniquely at x=3 until some other force starts acting on it. This means that, during a quantum computation, we should be cautious about the timing of our measurements – we cannot just peek at the data at any moment we like, or we risk disturbing a superposition. Importantly, this also means that a single piece of quantum memory cannot store an immense number of spreadsheets at the same time – at least, you wouldn’t be able to retrieve each of them. To store 15 MB worth of classical data, we need 15 MB worth of ‘qubits’. Hence, quantum computers are not particularly useful for storing classical data. The fact that a ‘measurement’ changes the state of the world poses a serious problem when engineering a quantum computer. No matter what material we construct our qubits from, they will surely ‘interact’ with other nearby particles, and some of these interactions could be destructive measurements. We call this effect decoherence, and we will later see that this forms one of the core challenges to building large and accurate quantum computers. At this point, quantum data doesn’t seem particularly useful. Why would we want to deal with superpositions if they lead to all this uncertainty? Intuitively, think about the advantage of a quantum computer in this way: what if we can jump between specific superposition states to reach our goal (the correct answer) in very few steps, exploiting states that a classical computer could never reach? . This is precisely what quantum operations do. These are physical forces that change the state of a particle or a quantum memory. They can turn a classical-looking state into a quantum superposition or vice versa. They can act like logical operations, such as AND and OR, but also like new quantum ‘logic’ that has no classical counterpart. Unlike measurements, quantum operations are deterministic: they change quantum states in a precisely defined way. In this book, we mainly deal with operations that work on qubits. We will call such operations quantum gates or simply ‘gates’. A quantum gate takes one or more qubits as input, changes their internal state, and then outputs the same number of qubits (with their altered states). In other words, the number of physical objects remains unchanged, but their quantum states change. As an example, you may think of our prototypical magnet that was initially pointing ‘up’, but a quantum gate might flip this to ‘down’. Because there are many possible quantum gates, each having a different effect on their input, we like to give them names in capital letters, such as X, Z, H, and CNOT. In the same jargon as the ‘quantum waves’, we can see quantum operations as manipulating these waves. This leads to effects similar to when you throw two stones in a pond, and look at how the resulting waves meet: when the peeks of two waves are at the same location, the water heights will add up. We call this constructive interference. But waves can also have ‘negative’ heights, where the water is lower than normal. Such parts may cancel an incoming peak: destructive interference. Quantum gates will have similar effects on a qubit’s quantum state, as negative and positive property assignments can interfere destrictively or constructively. The canonical way to describe a quantum computer program is by defining a sequence of quantum gates, one after the other, each of which could act on a different set of qubits. At the end of the computation, we measure all qubits. Below, an example of such a sequence is given, using the standard Quantum Assembly (QASM) language. Together, these steps can be graphically displayed in a quantum circuit, as shown here on the right. Quantum circuits represent each qubit with a horizontal line and indicate time flowing from left to right. Whenever a box with a letter is displayed over a qubit line, then the corresponding gate should be applied. This isn’t quite unlike the way we read sheet music! . Note that when we run a circuit on an actual quantum computer, the final measurements lead to probabilistic outcomes. We get to see a bunch of ones and zeroes: one classical bit for each qubit. If the circuit was a ‘good’ quantum algorithm, then with high probability, these classical bits will tell us the answer we were looking for. But even then, we might need to redo the computation a few times and take (for example) the most common result as our final answer. If you are completely confused at this point, you are not alone. The whole business of quantum superposition and quantum operations is incredibly complex and is not something you could possibly master after reading four pages. Even after studying the subject for many years, you will encounter paradoxes and counter-intuitive phenomena. On the other hand, I hope that the functionality of quantum circuits makes a lot of sense: we define a list of instructions, and we employ machines that execute these instructions in a well-defined way. This should be an example of how we can operate a quantum device without understanding what’s going on under the hood. There is one more quantum phenomenon to cover – one that comes with a mysterious flair around itself. We’re talking about quantum entanglement. Imagine that we have two qubits, which we can transport independently from each other without disturbing the data they store (in other words, they remain in the same quantum state). According to quantum mechanics, this pair of qubits may be simultaneously 00 and 11. Now, imagine that computer scientist Alice grabs one of the qubits, takes it on her rocket ship, and flies it all the way to dwarf planet Pluto. The other qubit remains on Earth, in the hands of physicist Bob. Upon arriving on Pluto, Alice measures her qubit and finds outcome ‘1’. A deep question is: what do we now know about the other qubit? . Since the possible measurement outcomes were 00 and 11, the other can only be measured as ‘1’ from now onwards. It essentially collapses to be 100% in the state ‘1’. But how could the earth-based qubit possibly know that a measurement occurred on Pluto? According to Einstein’s theory of relativity, information cannot travel faster than the speed of light, which translates into a few hours between Earth and Pluto. Nevertheless, measuring the qubit on earth will always give a consistent result, even when done within the hour. This paradox shows once again how confusing quantum mechanics can be. However, the story above is perfectly consistent with both quantum mechanics and relativity. The core principle is that no information can be sent faster than light between Alice and Bob. For example, can you see why Bob has no way of detecting when Alice reached Pluto just by looking at his entangled qubit? In the most common interpretation of quantum mechanics, the Earth qubit does indeed change its state instantaneously when Alice measures, although there is no way to exploit this effect. There’s a fascinating further discussion about the philosophy behind entanglement, but we’ll leave that to other sources. What matters to us is that distant qubits can still share specific properties that would be impossible classically, leading to new functionalities we can exploit. We will discover what these functionalities are in the chapter on quantum networks. So there you have it: four surprising phenomena you may hear frequently in quantum technology conversations. To summarise: . | Superposition: the phenomenon where a qubit is both 0 and 1 at the same time. | Quantum measurement: measuring a quantum memory destroys superposition. The result we obtain is probabilistic. | Quantum operations/gates: deterministic changes to the state of qubits, which generalise classical logic gates like OR, AND, NOT. A list of several quantum gates forms a quantum circuit. | Entanglement: Qubits separated over a long distance can still share unique properties. | . If you’d like to know more about the physics and math behind qubits, we recommend the following sources: . | Quantum Country – a great online textbook about Quantum Computing by Andy Matuschak and Michael Nielsen. | QuTech Academy’s School of Quantum – A broad range of topics explained using short videos.  . | . ",
    "url": "/part1/chapter_2/#an-introduction-to-the-quantum-world",
    
    "relUrl": "/part1/chapter_2/#an-introduction-to-the-quantum-world"
  },"12": {
    "doc": "2 An introduction to the quantum world",
    "title": "2 An introduction to the quantum world",
    "content": " ",
    "url": "/part1/chapter_2/",
    
    "relUrl": "/part1/chapter_2/"
  },"13": {
    "doc": "3 The background, why are we so enthusiastic about Quantum Technology?",
    "title": "The background: why are we so enthusiastic about Quantum Technology?",
    "content": "At a glance Quantum technology is an umbrella term for devices that exploit quantum phenomena like superposition and entanglement. The most notable innovations are expected in computers, networks, sensors, and simulators. Quantum computers will be much slower than conventional computers. Their advantage comes from the ability to run quantum algorithms, which solve specific problems in much fewer steps. What is quantum technology? . Quantum physics has already proven itself as an invaluable basis for technologies such as LED lighting, MRI scanners and solar cells. And it’s still relevant to push the limits of innovation, with nano-cars that consist of just a few atoms, or ever-smaller transistors on computer chips on the horizon. Just ahead of us is a new paradigm, which we’ll call quantum technology. The distinguishing factor is that it goes further than merely building stuff from small particles. Quantum technology is about devices that perform certain processes in a fundamentally different way. That is, the data (or operations) we work with can have special properties unique to quantum physics, such as superposition and entanglement. In our jargon, we will refer to ‘classical’ technology to mean devices that don’t carefully exploit the possibilities of quantum physics. Your laptop and phone are examples of classical computers, and they’re connected to the classical internet. The internal transistors and electrical circuits might be so tiny that quantum physics surely is relevant there, but the fundamental point is that the information that they process is purely classical. Whereas classical computers work with ‘bits’, quantum technology will store information in something called ‘quantum bits’, or shortly ‘qubits’. Generally, under the nomer of quantum technology, we distinguish four categories: . Quantum Computers . Quantum computers are devices that use quantum physics to perform automatic calculations to solve a problem. Computing is considered the most impactful application for most organisations, and therefore, it’s the main focus of this book.  . Quantum Networks . Quantum networks are connections between quantum devices over which qubits (or similar forms of quantum data) can be transmitted. The most relevant use case is to strengthen cryptography used by classical computers, but there are many more applications. Quantum Sensors . Quantum sensors are devices that exploit the effects of quantum physics to accurately measure certain quantities, such as a magnetic field or the strength of the earth’s gravity. Quantum clocks also fall into this category.  . Quantum Simulators . Quantum simulators are devices similar to quantum computers, except that they specialise in solving a limited set of problems. Typically, they are built to reproduce the behaviour of atoms and electrons in a molecule or a piece of material, allowing us to measure properties like energies and reaction rates. In this blog, we mainly focus on computers and networks: simply because these seem to have the biggest impact on typical (business) users. ### . The importance of high-performance computing . | (Computing allowed us to automate, industrialize, and scale up operations/production, leading to more wealth) . | Today’s computers are adequate for most purposes. But some could still be greatly improved with better computation: . | Chemistry R&amp;D . | Predicting the weather . | Scheduling, e.g. choosing which container to load on a cargo ship, or choosing which staff members should work which hours. | AI tasks, such as recognizing what’s on an image, or producing correct English texts . | …. | . | For many things, more compute power is not the solution . | Scheduling a meeting with many people . | Make devices crash less often . | . | Many are actually very hybrid: computing can help, but the core of the solution relies mostly elsewhere . | Reducing congestion (mostly solved by building more means of transport or changing human’s behaviour. | Solving climate change (new technology R&amp;D can help, but human behavioral change more important. | . | Not talking about small-scale computation (like running excel or a 3D game on a personal computer) . | In the foreseeable future, quantum computers will be used to solve ‘big’ problems using ‘big’ machines. We don’t expect portable devices (or ‘quantum accelarators’ in laptops or phones) any time soon. | . Image idea: venn diagram; ALL PROBLEMS – SOLVABLE BY COMPUTATION – STILL BENEFITS FROM MORE COMPUTE POWER – PROBLEMS WITH QUANTUM ADVANTAGE . ### . Why can quantum computers have an advantage?  . Quantum computers are devices that perform automatic computations at our command, very much like their classical counterparts. The ‘quantum’ part stems from the fact that it can actually exploit the laws of quantum mechanics. This should be contrasted to our conventional ‘classical’ computers, which technically can also be completely described by quantum mechanics, but they just happen to also work fine according to classical physics. By no means are they supposed to ever deal with quantum phenomena like superposition or entanglement. Contrarily, a proper quantum computer does exploit these purely quantum mechanical effects.  . A naive view of quantum computers is that they’re simply faster than their conventional cousins. Or perhaps one may naively point at Moore’s Law: with transistors reaching atomic scales, we run into quantum effects, hence quantum physics may help us make better chips. However, none of these are our core motivation to look at quantum computers.  . Firstly, quantum computers are much, much slower than conventional computers, if one focuses on their ‘time to perform a basic step’. A modern CPU can handle 64-bit numbers (meaning that all numbers between 0 and 264-1= 18,446,744,073,709,551,615 can processed in a single step). It can perform basic arithmetic like addition, multiplication, and so forth on these numbers, essentially in one single ‘step’. The speed of a modern CPU is incredible: a modern Intel or AMD processor works at a rate of several GHz, that is, several billions of steps per second. There’s no way a human can possibly keep up with such speeds when it comes to plain calculations!  . Now, quantum computers are supposed to be even faster, right? Well, it’s not hard to find backing for that claim:  . | Google creates quantum chip millions of times faster than the fastest supercomputer . | Chinese Scientists Create Quantum Processor 60,000 Times Faster Than Current Supercomputers . | . However, you may be disappointed to hear that quantum computers, at this moment, cannot even add or multiply numbers of more than 3 or 4 bits. And even if they could, their rate of operation would by no means reach several GHz, but more likely several MHz (a few million operations per second), at best. In other words, they’re more than a thousand times slower. To make things worse, the information in quantum computers is extremely fragile and requires to be constantly checked and corrected, using so-called error correction. This is a form of overhead that could make quantum computers another several orders of magnitude slower. Even in the far future, when quantum computers are more mature and more reliable, we still expect them to be much slower than the classical chips at that time.  . How does this rhyme with the news about ever-faster quantum computers? And why are we still interested in these slow machines? As we claimed before, we hope to do certain computations in a fundamentally different way. Let’s look at the following analogy that Andy Matuschak and Michael Nielsen bring up in their online course Quantum.country.  . Image source: https://commons.wikimedia.org/wiki/File:STS059-238-074_Strait_of_Gibraltar.jpg . Imagine that you’d like to travel from Morocco to Spain. If your technology does not allow you to cross the Strait of Gibraltar (say, you have access to a car but not a boat), then you’d need to take an incredible detour: all the way through North Africa, past the Arabian Peninsula, and through Europe, before you can reach your destination. This represents the steps taken by a classical algorithm. In the same analogy, a quantum computer grants you the ability to traverse both land and sea (much like a hovercraft). The fundamentally new possibilities that quantum offers allow us to do computations in fewer steps: even with a slower vehicle (computer), one may arrive at the destination sooner. In fact, this advantage often grows as problems become larger and more complicated. It is still an active area of research to completely map the landscape over which quantum computers can travel and, hence, to determine which problems can be sped up and which cannot.  . I like this analogy because it indicates that some problems can profit greatly from a quantum computer, whereas many won’t: you would not want to travel by hovercraft from Amsterdam to Berlin. For this reason, we don’t expect that classical computers will be ‘replaced’ any time soon: instead, different types of processors (CPUs, GPUs, quantum computers) are expected to co-exist. GPU and Quantum Processing Units (QPUs) are special-purpose devices, meant to only do tricks that they happen to be good at. In the analogy with the Strait of Gibraltar, the precise ‘route’ that you travel is the algorithm. More precisely, an algorithm is a step-by-step list of instructions that describes how a computational problem should be solved. The ‘steps’ here should be sufficiently simple so that it is completely unambiguously how to do them. Examples include operations such as adding, multiplying, or comparing two numbers. Needless the say, the fewer steps the algorithm requires, the better. By exploiting quantum mechanics, a quantum computer introduces new basic steps (like crossing the sea) that are impossible to perform on a classical computer. In the previous chapter, we saw specific quantum logic gates. Using these building blocks, we can formulate quantum algorithms that might take fewer steps than the best classical algorithm ever could! . From algorithm to software . In the end, simply finding the ‘recipe’ itself is not enough: the algorithm has to be turned into software, a piece of language that tells a computer explicitly how to execute the step-by-step instructions. The difference between ‘algorithms’ and ‘software’ is subtle. An algorithm is a purely mathematical description that describes precisely how numbers should be manipulated. It could tell which two numbers must be multiplied, what function must be evaluated, or how an image must be adjusted. However, different computers can use different types of processors and memory, and an algorithm does not describe how these operations are done on a specific computer. This is where software comes into play: it describes precisely what computer instructions must be called, where each number is stored in memory, and how an image is represented in binary. As an analogy, you may think of the algorithm as a recipe to bake the perfect chocolate cookie. The algorithm should unambiguously describe what should happen to the ingredients: in what order they should be mixed, how long they should be heated, etcetera. However, to build a factory that produces these cookies, you need to be even more specific: Where is the sugar stored? Out of what pipe does the dough flow? How are cookies laid next to each other in the oven? . Fundamentally, core scientific breakthroughs come from finding new algorithms. Once a new algorithm is found, it can be re-used many different times on any capable machine (assuming a good software developer will turn it into appropriate code!). In this book, we care less about quantum software and more about quantum algorithms. Firstly, the algorithms tell us precisely the functionality that quantum computers can offer. Moreover, we don’t yet know how a mature quantum computer will be programmed or how quantum hardware and software will change in the following years. On the other hand, the knowledge of algorithms can be cherished forever. Now that we have come to appreciate algorithms, it is natural to ask which quantum algorithms we know of. What problems do quantum computers solve well? And how to these algorithms compare to their classical equivalents? . Further reading . | The Map of Quantum Computing (Youtube)  – A 30-minute video that forms a great supplement to this book.  . | Chris Ferrie’s book ‘What You Shouldn’t Know About Quantum Computers’ . | Are you looking for a much more extensive source that covers pretty much everything there is to know about quantum computers? French consultant Olivier Ezratti maintains a 1300+ page book “Understanding Quantum Technologies”. | . ",
    "url": "/part1/chapter_3/#the-background-why-are-we-so-enthusiastic-about-quantum-technology",
    
    "relUrl": "/part1/chapter_3/#the-background-why-are-we-so-enthusiastic-about-quantum-technology"
  },"14": {
    "doc": "3 The background, why are we so enthusiastic about Quantum Technology?",
    "title": "3 The background, why are we so enthusiastic about Quantum Technology?",
    "content": " ",
    "url": "/part1/chapter_3/",
    
    "relUrl": "/part1/chapter_3/"
  },"15": {
    "doc": "4 The applications, What problems will we solve with quantum computers?",
    "title": "The applications: What problems will we solve with quantum computers?",
    "content": "At a glance . | Four key applications in IT are: simulation of chemistry and materials, cracking cryptography, using quantum networks to distribute cryptographic keys, and solving large-scale optimization and AI problems.  . | Not every quantum speedup is useful: a much faster classical computer is often a better choice. In optimisation and AI, we have not found a truly valuable ‘killer application’ yet. | . In the previous part, we saw that quantum computers are extremely slow computers, but they happen to solve some problems more efficiently, that is, in fewer steps. The most important question in this field is: what advantage do quantum computers have on which problems? To answer this question, we break it down into two parts: . | What are projected applications with a quantum speedup? . | How large is the advantage of known speedups? . | . What are projected applications with a quantum speedup? . We foresee four major use cases where quantum computing can make a real impact on society. We briefly discuss each of them here and link to a later chapter that discusses each application in more depth.  . 1. Simulation of other quantum systems: molecules, materials, and chemical processes . Most materials can be accurately simulated on classical computers. However, in some specific situations, the locations of atoms and electrons become notoriously hard to describe, sometimes requiring quantum mechanics to make useful predictions. Such problems are the prototypical examples of where a quantum computer can offer a great advantage. Realistic applications could be in designing new chemical processes (leading to cheaper and energy-efficient factories), estimating the effects of new medicine, or working towards materials with desirable properties (like superconductors or semiconductors). Of course, scientists will also be excited to simulate the physics that occur in exotic circumstances, like at the Large Hadron Collider or in black holes. Simulation is, however, not a silver bullet, and quantum computers will not be spitting out recipes for new pharmaceuticals by themselves. Breakthroughs in chemistry and material science will still require a mix of theory, lab testing, computation, and most of all, the hard work of smart scientists and engineers. From this perspective, quantum computers should become a useful new tool for R&amp;D departments. Read more: How can quantum computers help us produce agricultural fertiliser more efficiently? . See also: . | Startup PhaseCraft studies the famous Fermi-Hubbard model using a quantum computer . | Startup Zapata reduces the runtime and error rate of famous chemistry algorithm . | IBM and Daimler research next-gen batteries . | Roche started a project to find medicines for Alzheimer’s . | An overview of various simulation software packages for quantum computers . | . 2. Cracking a certain type of cryptography . The security of today’s internet communication relies heavily on a cryptographic protocol invented by Rivest, Shamit and Adleman (RSA) in the late 70s. The protocol helps distribute secret encryption keys (so that nobody else can read messages in transit) and guarantees the origin of files and webpages (so that you know that the latest Windows update actually came from Microsoft, and not from some cybercriminal). RSA works thanks to an ingenious mathematical trick: honest users can set up their encryption using relatively few computational steps, whereas ‘spying’ on others would require one to solve an extremely hard problem. For the RSA cryptosystem, that problem is prime factorisation, where the goal is to decompose a very large number (for illustration purposes, let’s think of 15) into its prime factors (here: 3 and 5). As far as we know, for sufficiently large numbers, this task can take a classical computer such a long time that nobody would ever succeed in breaking a relevant code – think of thousands of years. RSA was deemed adequately secure, at least, until computer scientist Peter Shor discovered that quantum computers are quite good at factoring. The quantum algorithm by Shor can crack RSA (and also its cousin called elliptic curve cryptography) in a relatively efficient way using a quantum computer. To be more concrete, according to a recent paper, a plausible quantum computer could factor the required 2048-bit number in roughly 8 hours (and using approximately 20 million imperfect qubits). The authors had to make several assumptions about what a future quantum computer would look like, and did so in a very prudent way: picking realistic properties of prospective hardware, and using the most up-to-date knowledge of error correction and compiling. Note that future breakthroughs will likely further reduce the stated time and qubit requirements. Luckily, not all cryptography is broken as easily by a quantum computer. RSA falls in the category of public key cryptography, which delivers a certain range of functionalities. A different class of protocols is symmetric key cryptography, which is reasonably safe against quantum computers but doesn’t provide the same rich functionality as public key crypto. The most sensible approach is replacing RSA with so-called post-quantum cryptography (PQC): public-key cryptosystems resilient to attackers with a large-scale quantum computer. Interestingly, PQC does not require honest users (that’s you) to have a quantum computer: it will work perfectly fine on today’s PCs, laptops and servers. Read more: How will quantum computers impact cybersecurity?  . See also: . | MinutePhysics has a fantastic (but technical!) explainer of Shor’s algorithm.  . | NIST’s competition to standardize new public-key algorithms    . | Nature feature article: The race to save the Internet from quantum hackers . | .   . During the following decade, every large organisation will have to worry about updating to post-quantum cryptography – a complex migration that comes in addition to the many existing cybersecurity threats. The American National Institute of Standards and Technology (NIST) runs a competition to select a new standard that is adequate for most applications. Nevertheless, many organisations run a vast amount of legacy software that is hard to update, so completing this update in the upcoming ~8 years poses a complex operational challenge. For this reason, organisations are encouraged to start this process as early as possible.  . A new type of cryptography poses additional risks: it has not yet been tested as thoroughly as the nearly 50-year-old RSA standard. Ideally, new implementations will be hybrid, meaning that they combine the security of a conventional and a post-quantum algorithm. On top of that, organisations are encouraged to adopt cryptographic agility, meaning that cryptosystems can be easily changed or updated if the need arises.  . Read more: What steps should your organisation take? . Other great sources are: . | The PQC Migration Handbook, written by the Dutch secret service AIVD and research organizations CWI and TNO. | Cloudflare tracks the adoption of post-quantum cryptography and explains many technical details extremely well.  . | US National Institute for Standards and Technology (NIST): Getting Ready for Post-Quantum Cryptography: Explore Challenges Associated with Adoption and Use of Post-Quantum Cryptographic Algorithms . | UK National Cyber Security Center: Preparing for Quantum-Safe Cryptography . | BSI (German secret service): Quantum-safe cryptography – fundamentals, current developments and recommendations . | NCSC (Dutch National Cyber Security Center): Factsheet Postquantumcryptografie [NL] . | . 3. Quantum Key Distribution to strengthen cryptography . Out of all the applications for quantum networks, Quantum Key Distribution (QKD) is the one to watch. It allows two parties to generate secure cryptographic keys together, which can then be used for everyday needs like encryption and authentication. It requires a quantum network connection that transports photons in fragile quantum states. Such connections can currently reach a few hundred kilometres, and there is a clear roadmap to expand to a much wider internet. The most likely usage will be as an “add-on” for high-security purposes (such as military communication or data exchange between data centres), in addition to standard post-quantum cryptography.  . Unfortunately, we often see media articles suggesting that QKD is a solution to the threat of Shor’s algorithm and that it would form an ‘unbreakable internet’. Both claims are highly inaccurate. Firstly, QKD does not offer the wide range of functionality that public-key cryptography offers, so it is not a complete replacement for the cryptosystems broken by Shor. Secondly, there will almost certainly be ways to hack a QKD system (just like with any other security system). Then why bother with QKD? The advantage of QKD is based on one main selling point: contrary to most other forms of cryptography, it does not rely on mathematical assumptions. This can be an essential factor when someone is highly paranoid about their cryptography, or when data has to remain confidential for an extremely long period of time.  . At this time, pretty much every national security agency discourages the use of QKD simply because the available products are far from mature (and because PQC should be prioritised). It is unclear how successful QKD could be in the future—we will discuss this in depth in a next chapter. Read more: What are the use cases of quantum networks? . See also:  . | A short video explainer about how QKD works. | The NCSC states that it “does not endorse the use of QKD for any government or military applications” . | The French ANSSI, German BSI, Dutch NLNCSA and Swedish SNCSA published a critical position paper on QKD in 2024.  . | . Quote: . Major security agencies do not support the use of QKD to secure communications and agree that post-quantum cryptography should be regarded as the best way to mitigate the quantum threat. THE PQC MIGRATION HANDBOOK . End quote . We firmly warn that other security products with the word “quantum” in the name are no guarantee for protection against Shor’s algorithm. In particular, “quantum random number generators” (QRNGs) are sometimes promoted as a saviour against the quantum threat, which is nonsense. These devices serve a completely different purpose: they compete with existing hardware to generate unpredictable secret keys, which find a use (for example) in hardware security modules in data centres.  . See also:  . | Samsung builds QRNGs into certain phones on the South Korean market.  | . 4. Optimisation and machine-learning . This is the part where most enterprises get excited: Can we combine the success of AI and machine learning with the radically new capabilities of quantum computers? Classical optimisation and AI techniques have had an incredible impact in many areas, from optimising train schedules to detecting fraud, from training chatbots to accurately predicting the weather.  . Under the hood, all such applications are based on concrete mathematical problems such as (discrete) optimisation, differential equations, classification, and optimal planning. For conciseness, we collectively refer to these problems (including machine learning tasks) as ‘optimisation’. The classical field of optimisation is of great importance and takes up a significant fraction of the world’s computational resources! . Contrary to the many classical successes, the impact of quantum optimisation or machine learning is not yet clear. To better understand the available algorithms, we will consider three different categories.  . Rigorous but slow algorithms . Many quantum optimisation algorithms have a well-proven quantum speedup: there is no dispute that these require fewer computational steps than any classical algorithm. For instance, a famous quantum algorithm invented by Lov Grover (with extensions by Durr and Hoyer) finds the maximum of a function in fewer steps than conventional brute-force search. Similarly, quantum speedups were found for popular computational methods such as backtracking, gradient descent, semidefinite programming, lasso, and interior point methods for solving differential equations.  . The main question is whether this also means that the quantum computer requires less time! All of the above optimisation algorithms offer a so-called polynomial speedup (in the case of Grover, this is sometimes further specified to be a quadratic speedup). As we will soon see, it is not entirely clear if these speedups are enough to compensate for the slowness of a realistic quantum computer – at least in the foreseeable future.  . | ***Heuristic algorithms ** On the other hand, some algorithms claim much larger speedups, but there is no undisputed evidence to back this up. Often, these algorithms are tested on small datasets using the limited quantum computers available today – which are still so tiny that not much can be concluded about larger-scale problems. Nonetheless, these ‘high risk, high reward’ approaches typically make the bold claims that receive media attention. The most noteworthy variants are: . | Variational quantum circuits (VQC) are relatively short quantum programs that a classical computer can incrementally change. In jargon, these are quantum circuits that rely on a set of free parameters. The classical computer will run these programs many times, trying different parameters until the quantum program behaves as desired (for example, it might output very good train schedules or accurately describe a complex molecule). The philosophy is that we squeeze as much as possible out of small quantum computers with short-lived qubits: the (fast) classical computer takes care of most of the computation, whereas the quantum computer runs just long enough to sprinkle some quantum magic into the solution. Although its usefulness is disputed, this algorithm is highly flexible, leading to quantum variants of classifiers, neural networks, and support vector machines. Variants of this algorithm may be found under different names, such as Quantum Approximate optimisation Algorithm (QAOA), Variational Quantum Eigensolver (VQE), and quantum neural networks.  . | Quantum annealing solves a particular class of optimisation problems. The problem is encoded into a physical system (in jargon: a Hamiltonian) so that at very low temperatures, the physical system somehow describes a solution to the problem. For example, when finding the optimal locations to place mobile phone masts, a qubit in the state “1” might indicate a good site. A quantum annealing algorithm is a smart way to ‘make’ such a low-temperature system (often by starting in a setting where it’s trivial to ‘cool’ and then slowly introducing the complex forces corresponding to the target system). Annealing itself is a mature classical algorithm. The advantage of a ‘quantum’ approach is not immediately apparent, although there are claims that hard-to-find solutions are more easily reached thanks to ‘quantum fluctuations’ or ‘tunnelling’. Quantum annealing was popularised by the Canadian company D-Wave, which builds dedicated hardware with up to 5000 qubits and offers a cloud service that handles relatively large optimisation problems.  . | .   . Fast solutions in search of a problem . Lastly, there exist algorithms with large speedups, for which we are still looking for use-cases with any scientific or economic relevance. The most notable example is the quantum algorithm for topological data analysis (a method to assess certain global features of a dataset), which promises an exponential advantage under certain assumptions. However, to our best knowledge, no interesting datasets have been found that fit the algorithm’s requirements. A fourth class: quantum-inspired algorithms . Some impressive speedups that were recently found have been ‘dequantized’: these algorithms were found to work on classical computers too! There’s a beautiful story behind this process, where Ewin Tang, a Master’s student at the time, made one of the largest algorithmic breakthroughs of the decade. A great report can be found here: https://medium.com/qiskit/how-ewin-tangs-dequantized-algorithms-are-helping-quantum-algorithm-researchers-3821d3e29c65 . Unfortunately, there does not yet exist an optimisation algorithm with obvious economic value: all of them come with serious caveats. This perspective is perhaps a bit disappointing, especially in a context where quantum computing is often presented as a disruptive innovation. Our main takeaway is that quantum optimisation (especially quantum machine learning!) is rather over-hyped.  . Of course, there are still good hopes that we will find new algorithms and applications. To truly understand this field, we should examine the prospects of finding a new ‘killer algorithm’. The next section becomes slightly more technical and helps us quantify the amount of ‘quantum advantage’ that different algorithms have.  .   . Further reading:  . | Volkswagen and ExxonMobil used annealing to optimise routes for buses and transport ships. | Professor Scott Aaronson warns us to ‘Read the fine print’ of optimisation algorithms. [Appeared in Nature Physics, with paywall]  . | Professor Sanker Das Sarma warns of hype within the field of quantum optimisation and machine learning. | . How large is the advantage of known speedups?  . When looking at the applications of quantum computers, one should always keep in mind: Are these actual improvements over our current state-of-the-art? Anyone can claim that their algorithm can solve a problem, but what we really care about is whether it solves it faster. Classical computers are already extremely fast, so quantum algorithms should offer a substantial speedup before they become competitive.  . What does an “algorithmic speedup” mean? . We can assess algorithms by their so-called “asymptotic complexity”: As a problem becomes ‘bigger’, how much longer does a computation take? The main figure of merit is how this scales towards very large sizes.  . For every instance of a problem, we can define a ‘size’ that influences the difficulty. For example, computing 54 x 12 is much easier than 231.423 x 971.321, even though they’re technically the same problem, and we’d use the very same multiplication algorithm. Similarly, creating a work schedule for a team of 5 is simpler than dealing with 10.000 employees. We typically use the letter ‘n’ to denote the problem size. You can see n as the number of digits in a multiplication (like 2 or 6 above) or the number of employees involved in a schedule.  . For some very hard problems, the time to solution takes the form of an exponential: T ~ en, where T is the time taken. Exponential scaling is typically a bad thing, as the function en becomes incredibly large even for moderate values of n. The problem of factoring (on a classical computer) scales somewhat similar to T ~ en.  . There are also problems for which the scaling looks like a polynomial, like T ~ n3 or T ~ n2. Polynomials grow much slower than exponentials, making it easier to solve large problems in a reasonable amount of time. The problem of factoring on a quantum computer takes scales roughly as T ~ n3 (thanks to Shor’s algorithm*). Because a quantum computer brought the exponential down to a polynomial, we call this an ‘exponential speedup’. Such speedups are a computer scientist’s dream because they have an incredible impact on practical runtimes.  . Often, we deal with ‘merely’ a polynomial speedup, which happens when we obtain a smaller polynomial (for example, going from T ~ n2 towards T ~ n), or perhaps even a ‘smaller’ exponential function (like T ~ en towards T ~ en/2. Reducing the exponent by a factor of two (like n2 -&gt; n) is also sometimes called a quadratic speedup (which is precisely what Grover’s algorithm gives us). Further reading: . | At a more coarse level, we can define different “complexity classes”.  | .    * You may find even sources stating smaller polynomials, like n2 log(n). These are theoretically possible but rely on asymptotic optimizations that are unlikely to be used in practice. Here is a rough overview of quantum speedups as we understand them today, categorised by their type of speedup: .   . 🟢   The “exponential” box is the most interesting one, featuring applications where quantum computers seem to have a groundbreaking advantage over classical computers. It contains Shor’s algorithm for factoring, explaining the incredible advantage that quantum computers have in codebreaking. We also believe it contains some applications in chemistry and material science, especially those relating to dynamics (studying how molecules and materials change over time).  . 🟡   The “polynomial” box is still interesting, but its applicability is unclear. Recall that a quantum computer would need much more time per step – and on top of that, it will have considerable overhead due to error correction. Does a polynomial reduction in the number of steps overcome this slowness? According to a recent paper, small polynomial speedups (as achieved by Grover’s algorithm) will not cut it, at least not in the foreseeable future.  . 🔴   For some computations, a quantum computer offers no speedup. Examples include sorting a list or loading large amounts of data.  . If this were the complete story, then most people would agree that quantum computing is a bit disappointing. It would be a niche product for hackers and a tiny community of physicists and chemists who study quantum mechanics itself.  . ⚪   Luckily, there is yet another category: many of the most exciting claims come from the heuristic algorithms. This term is used when an algorithm might give a suboptimal solution (which could still be useful), or when we cannot rigorously quantify the runtime. Such algorithms are quite common on classical computers: neural networks fall in this category, and these caused a significant revolution in AI. Unfortunately, it is unclear what the impact of currently known heuristic quantum algorithms will be.  . See also: . | A quantitative analysis of Grover’s runtime compared to today’s supercomputers.  . | (Technical!) Amazon researchers lay out a comprehensive list of end-to-end complexities of nearly every known quantum algorithm. | . Where is the killer application? . For a quantum algorithm to be truly impactful, we require two properties:  . | [Useful] The algorithm solves a problem with real-world significance (for example, because organisations can work more efficiently or because it helps answer scientific questions). | [Better/faster] Out of all the possible approaches, this algorithm is the most attractive solution. This is achieved when a realistic quantum computer solves the problem faster than any classical machine could, but other aspects like energy consumption or total cost of hardware and software development can also play a role. This most likely requires an exponential speedup, or a large polynomial speedup.  . | . Several algorithms, most notably Grover’s algorithm and VQE’s, have a very wide range of industrial applicability. However, it seems that in practice, other (classical) approaches solve such problems faster and more cheaply.  . Then there exist exponential speedups, like the algorithm for topological data analysis, for which no practical uses have been found (despite many scientific and industrial efforts).  . To our best knowledge, only codebreaking (Shor’s algorithm) is both exponentially faster and extremely impactful. Unfortunately, this is primarily a negative application that helps criminals – we are not aware of any positive uses of Shor, hence this is not quite the killer application that we’re looking for.  . Even in chemistry, it is hard to pinpoint a convincing application. Classical computers are already incredibly fast, and very good classical algorithmic techniques have been developed. Scientist Garnet Chan gives talks which are suggestively titled “Is There Evidence of Exponential Quantum Advantage in Quantum Chemistry?”.  . Could the nature of quantum mechanics be such that it helps us in codebreaking, but in literally nothing else? We think that such a scenario is unlikely. It seems that a killer algorithm has not yet been found, but there are good reasons to hope that we will find one in the future. Perhaps we need novel mathematical tools, or perhaps we simply need to play around on increasingly mature quantum hardware. We hope that we’ll have to incrementally update this page over the coming years, as we slowly uncover the complete set of capabilities that quantum computers have! . ",
    "url": "/part1/chapter_4/#the-applications-what-problems-will-we-solve-with-quantum-computers",
    
    "relUrl": "/part1/chapter_4/#the-applications-what-problems-will-we-solve-with-quantum-computers"
  },"16": {
    "doc": "4 The applications, What problems will we solve with quantum computers?",
    "title": "4 The applications, What problems will we solve with quantum computers?",
    "content": " ",
    "url": "/part1/chapter_4/",
    
    "relUrl": "/part1/chapter_4/"
  },"17": {
    "doc": "5 Timelines, When can we expect a useful Quantum Computer?",
    "title": "Timelines: When can we expect a useful Quantum Computer?",
    "content": "The billion-dollar question in our field is: . When will quantum computers outperform conventional computers on relevant problems? . Unfortunately, nobody really knows. We could give, say, 2036 as a reasonable estimate, and many people may clamp hope to such estimations. You may even jump straight to our conclusions. However, these numbers strongly rely on unpredictable breakthroughs, and past predictions regularly proved inaccurate. Moreover, a relevant quantum computer won’t just suddenly appear: there’s a continuous evolution where these devices will become increasingly capable. That’s why, in this chapter, we address how future predictions are made, and what will happen on the path towards large-scale quantum computation.  . What parameters are relevant? . Compared to currently available technology, we’d require a fundamental improvement to these specifications: . | Number of qubits . | Accuracy of elementary operations (i.e.: ability to perform long computations without making mistakes). Sufficient accuracy likely requires error correction. | . In the following, we may use the term quantum gate to mean one elementary operation on a quantum computer. You should compare these quantum gates to their classical counterparts, like NOT and OR that you may find in classical electronics. There are quite a few other parameters that matter (such as the connectivity, the available set of gates, the speed of operations, and so forth). We choose to simplify matters by presenting a limited perspective with just the number of qubits and gate accuracies, which is sufficient a rough estimate. The relevance of accuracy is often overlooked, perhaps because this hardly plays a role for classical computers (which operate perfectly for basically all intents and purposes). The problem is as follows: every gate we perform on the quantum computer has a small chance of introducing an error. The more steps a computation takes, the larger the chance that the computation fails. In other words: harder problems put more stringent requirements on the quantum computer’s hardware, and require more accurate operations. Of course, our main focus is on massive-scale computational problems that take hours or even weeks on classical machines.  . Wait! What exactly is this ‘accuracy’? . To illustrate, imagine a quantum computer where each elementary step (“gate”) has a 1:1000 chance to introduce an error. This computer may suffice for computations of merely 100 gates, but as soon as of the order of 1000 or more gates are needed, the probability that the computer’s output is incorrect becomes quite significant. What if we need to run a circuit of 1 million gates? If the computer has sufficiently many qubits, we will use error correction to lower the probability of error to much less than one-in-a-million. We often state the ‘error’ of a gate, rather than the ‘accuracy’. For example, a gate with 1% chance of error can be said to have 99% ‘accuracy’. Scientists like to define these numbers more precise by talking about gate fidelities or coherence times. Luckily, there is a well-established field of quantum error correction. It allows us to combine many ‘physical qubits’ available on the device (think of the order of 1000) into a single, more accurate ‘logical qubit’, on which gates have a smaller chance of error (say, by a factor 1 billion). This allows much longer computations. Error correction allows a trade-off between the number of available qubits and gate accuracy. For more details, see the chapter on error correction.  . In this chapter, we simplify the predictions down to only the number of physical qubits, so that we have a single parameter to study. This means that, for longer computations (or better accuracies), we accounts for additional qubits to achieve the necessary gate accuracies. Back to the main question: When can we expect a large quantum computer? . For now, let’s keep things relatively simple, and break our billion-dollar question into two parts: . | How many qubits do we need for relevant applications? . | How long will it take before we have that many qubits? . | . How many qubits are needed? . In Part 2, we discussed the three main applications of quantum computers: quantum simulation, breaking cryptography, and optimization. The most concrete numbers can be given for Shor’s algorithm (breaking cryptography), where we have a very clear problem to tackle: obtain a private (secret) key from a widely-used cryptosystem, like the RSA-2048 protocol. This is the perfect benchmark because there can be no discussion about whether the problem is solved: one either obtains the correct key, or one doesn’t. Moreover, for this benchmark, we’re quite convinced that even the best classical computers can’t solve the problem (or else we you shouldn’t use internet banking or trust software updates).  . A recent estimate finds that a plausible quantum computer would require roughly 20 million ‘reasonably good’ physical qubits to factor a 2048-bit number. The whole computation would take about 8 hours. Such estimates require several assumptions on what a quantum computer would look like in the future. In this case, the authors assume qubits are built using superconducting circuits, which are laid out in a square grid. Error correction is assumed to be done using the so-called surface code, assuming the best-known methods for error correction in 2020. Note that future breakthroughs could reduce the required time and number of qubits even further. For chemistry and material simulation, it’s a lot harder to give estimates, because there is not just a single problem to tackle here: one typically uses computers to gradually improve our understanding of a complex structure or chemical reaction. This should be combined with theoretical reasoning and practical experiments. Moreover, classical computers are often able to perform the same computations that the quantum computer would make, at the cost of making certain assumptions or simplifications. There’s a fuzzy region between ‘classically tractable’ and ‘quantum advantage’. One way to define a concrete task is to ask for the energetic cost of certain molecular configurations. The benchmark here is to provide energies more accurately than done in conventional experiments: one canonically takes the ‘chemical accuracy’ of roughly 1 kcal/mol as the precision to beat. Then, of course, we should focus on molecules where classical computers cannot already achieve such accuracies.    . Note that the accuracy of a chemical energy should not be confused with the accuracy of a quantum gate, which is a whole different number. A highly promising and well-studied benchmark problem is the simulation of the so-called FeMo cofactor, in short: FeMoco. This molecule is relevant when bacteria produce Ammonia (NH3), a compound that is of great relevance to a plant’s root system. A better understanding of this process could help us reduce the ridiculously large carbon emissions now associated with the production of artificial fertilizer. We give more details in a separate chapter.  . Simulation of FeMoco is believed to require around 4 million qubits (and around 4 days of computation for a single simulation run). Assumptions of the hardware and error correction are similar to the case of Shor’s algorithm: the estimate is based on a square grid of superconducting qubits, using surface code as the method to correct errors. For a different enzyme, namely cytochrome P450, it has been estimated that around 5 million qubits are needed (again taking roughly 4 days of computation). Altogether, we conclude that a couple million qubits (of sufficiently high quality) may make quantum computers relevant for R&amp;D in chemistry.  . Further reading: . | A case study of FeMoco as a killer application for quantum computers . | University of Leiden’s research page on why simulating FeMoCo is the Killer Application for quantum computers. | . For many optimization problems, it’s practically impossible to give reasonable estimates. For one, a true killer algorithm for optimization problems is not known yet. The algorithms that are presented as the most promising are often heuristic, meaning that scientists do not know how long an algorithm will take to find solutions. This can happen, for example, when an algorithm repeats a certain loop until a stopping criterion has been met. This may come as a shock, considering the many news items that report how quantum computers may already solve practical problems. But don’t be fooled: these articles state that quantum computers can indeed solve relatively simple problems, but often fail to mention that there exist different approaches by which classical computers can solve the same problems much, much faster.  . Many optimization problems have a plethora of potential solutions, but the goal is to find the optimal solution (say, the one that incurs the least costs or gets you to your destination the fastest). The solution space is often so large that we don’t even know if we hit the optimal solution, but we’re okay with finding one that’s pretty close. Several papers claim that a quantum computer already finds solutions faster, but in all cases, worrying sacrifices were made for the optimality of the solutions. One of the leading sources of wild claims is D-Wave’s quantum annealer. This is a ‘limited’ quantum computer that cannot run every quantum algorithm, but it’s extremely good a one specific algorithm, called “quantum annealing”. With around 5000 qubits, it can handle reasonably large problems, and several companies have tried their hands at this machine. The results obtained through today’s quantum annealing approaches are likely much more easily achieved by putting a similar amount of effort into a good classical solution. | Application | How well can we estimate qubit requirements? | Use case example | Qubits needed? | Gate error assumed? | . | Breaking cryptography | Good | Cracking RSA-2048 | ~ 20 million | ~ 0.1% | . | Chemistry | Reasonable | Simulation of FeMoco | ~ 4 million | ~ 0.1% | . | Optimization / AI | Bad | ? | ? |   | . What about NISQ machines? . Current quantum computers are somewhat small and not yet capable of large-scale error correction: they are Noisy Intermediate Scale Quantum (NISQ) devices. Several parties claim that these devices may already perform useful computations without error correction. So far, we have not seen convincing evidence, but it is certainly possible that future breakthroughs make this possible. If so, quantum computers would become useful even sooner than we predict here.  . Further reading: Professor Sankar Das Sarma on the lack of convincing NISQ applications. How long until we have million-qubit machines? . We highlight a few sources that we can use to predict technological developments: . | Road maps and claims of hardware manufacturers . | Surveys to experts . | Extrapolation of Moore’s law . | . What do manufacturers say? . IBM has the most explicit road map. As of 2022, they predict to have over 1000 qubits by 2023, and 1 million qubits in 2030. Google even thinks of building a 1M qubit device by 2029. Unfortunately, such claims often cannot be found on the manufacturer’s websites, but are taken by journalists from talks and presentations. Both Google and IBM work on superconducting qubits. Similarly, a start-up called PsiQuantum is reported to work towards a million photonic qubits by 2025, which seems somewhat unlikely because the company has not publicly demonstrated any successes so far.   . IonQ displays its road map in a different format: they aim to have 1024 algorithmic qubits by 2028. This means that IonQ will have at least this number of qubits, but also guarantees sufficient gate accuracy to be able to run reasonably long circuits. It’s unclear whether a simple form of error correction may be needed to achieve this. If so, the actual number of physical qubits may be some orders of magnitude higher. Quantinuum (previously Honeywell Quantum Solutions) makes less concrete predictions, but expects fault-tolerant computing by 2030 (meaning that significant error correction is in place). In terms of today’s hardware, Quantinuum holds a record with roughly 19 algorithmic qubits. In the figure below, we plot the road maps of Google and IBM, and compare these to Moore’s law. What does Moore’s law say? . One could assume that quantum computers will ‘grow’ at a similar rate as classical computers. Moore’s law states that the number of transistors in a dense integrated circuit grows exponentially: the number doubles roughly every two years. This has been a surprisingly accurate predictor for the development of classical IT. If we apply Moore’s law to quantum, to get from 100 to 1M qubits would require 28.5 years – predicting that the 1M mark won’t be passed until 2048. Clearly, most hardware manufacturers are more optimistic. If we assume the number of qubits doubles each year, one would predict that 1M-qubit machines will be available around 2035. While doubling a quantum computer’s size each year is already a daunting challenge, IBM and Google set the bar even higher for themselves, hoping to double every 7-9 months. What do experts say? . The Global Risk Institute conducts yearly surveys, asking experts to state the likelihood that quantum computers pose a significant threat to public-key cryptography 5 years from now. Similarly, respondents would also estimate the likeliness 10, 15, 20, and 30 years away. This essentially boils down to the question: when will a quantum computer be built that can run Shor’s algorithm to crack RSA-2048? We previously saw that around 20 million qubits would be needed for this. The results from December 2023, gathered from 37 quantum experts from academia and industry, are displayed below. Figure credits: GlobalRiskInsitute.org. How to read this graph? . Let’s look at the column labeled ‘5 years’. A total of 24 correspondents indicate that there is less than 1% chance that quantum computers pose a security threat in the next five years. A single person is quite pessimistic and assigns &gt;70% chance that this will happen. On average, experts say that there’s a fairly small chance that quantum computers will pose a threat to cryptography in the next 5 years.  . Further to the right, the ratios shift: looking at 20 years from now, the majority of experts believe that quantum computers pose a serious threat: over half of them assign a likelihood of 70% or more. It appears that the majority of experts believe that the tipping point is between 10-20 years from now. We could pick 3036 (15 years from now) as a point where experts assign, on average, a roughly 50% chance to see a quantum computer capable of running Shor’s algorithm.  However, we should take into account a significant uncertainty: several experts make wildly varying estimates, and there’s no clear conclusion about the quantum computer’s impact in the next 30 years. These experts are likely aware of hardware manufacturer’s road maps and make predictions that seem well in line with IBM’s vision on hardware, as we shall see below. Conclusion: when will a quantum computer solve relevant problems? . In the figure below, we extrapolate IBM’s road map, assuming the same doubling time of roughly every eight-and-a-half months. We also indicate the predictions of Moore’s law with a doubling time of 1 or 2 years. If IBM manages to adhere to its road map, relevant applications like cracking RSA and simulating FeMoco should be possible in the early 2030s. This holds, provided that gate accuracies and error correction are also evolving at a commensurate pace.  . However, the exponential nature of qubit growth makes timeline predictions strongly dependent on the doubling time. If we assume regular Moore’s law (with a doubling time of 2 years), one shouldn’t expect 4 million qubits before the 2050s. The ‘majority’ expert prediction according to the Global Risk Institute is separately indicated in the region around around 2033-2039 (light red area). It sits largely in between the pace of IBM and the yearly doubling version of Moore’s law.   . Final words . Our analysis has its limitations: we considered just two use-cases of a quantum computer (which happen to be well-studied), but it is not unlikely that new, shorter-term applications will be found. Nevertheless, we believe that the above data gives a fairly accurate outlook of future developments. Optimists may follow manufacturer’s roadmaps, pessimists will point at the 2-year doubling time of Moore’s law, and the truth is likely somewhere in between: we consider somewhere in the 2030s or early 2040s seems a reasonable estimate for relevant large-scale quantum computers. We stress that such estimates assume that there is not just a race for the largest numbers of qubits, but that gate accuracies and error correction implementations should evolve along at a similar pace.  . ",
    "url": "/part1/chapter_5/#timelines-when-can-we-expect-a-useful-quantum-computer",
    
    "relUrl": "/part1/chapter_5/#timelines-when-can-we-expect-a-useful-quantum-computer"
  },"18": {
    "doc": "5 Timelines, When can we expect a useful Quantum Computer?",
    "title": "5 Timelines, When can we expect a useful Quantum Computer?",
    "content": " ",
    "url": "/part1/chapter_5/",
    
    "relUrl": "/part1/chapter_5/"
  },"19": {
    "doc": "1 Chemistry, A case study of artificial fertiliser",
    "title": "Chemistry: A case study of artificial fertiliser",
    "content": "Perhaps the most credible applications of quantum computers is the simulation of chemistry and material science. The advantage is especially large when a large number of electrons engage in a complex quantum mechanical state. In such situations, quantum mechanics is notoriously hard to simulate on a classical computer: accurately describing N particles requires a number of computational steps that scales exponentially in N. The quantum computer is not troubled by such inefficiencies, and scientists find increasingly detailed descriptions of how one could obtain faster tools to study complicated materials and molecules. Again, there are good arguments to be skeptical about the impact of quantum computers. Computational chemistry has seen many years of developments and optimizations to work around the classical computer’s bottlenecks, which has raised a high bar before a quantum computer can contribute meaningful insights. A true near-term killer application is likely to be limited to a very specific niche, right in a sweet spot where classical methods remain limited. For precisely these uses cases, one may find the most concrete evidence that quantum computers can usefully outperform classical computers. To highlight a well-studied and highly relevant example, we dive into the world of artificial fertilizer. The case of FeMoco . Chemical structure of the FeMo cofactor, taken from Wikimedia. Today’s agriculture relies heavily on the use of artificial fertilizer to grow our crops. Without large-scale use of supplementary nutrients, it would be problematic to feed our world’s huge population. In fact, about half of the nitrogen atoms in our body have previously passed a fertilizer factory! . Unfortunately, the production of fertilizer involves enormous energy consumptions and carbon emissions. The main culprit is the ingredient ammonia (NH3), of which we use as much as 230 Mton per year. Although our air consists mainly of molecular nitrogen (N2), plants cannot directly absorb this. Instead, they rely on bacteria (or, in the case of artificial fertilizer, humans) to perform so-called nitrogen fixation, breaking the strong triple bond of molecular nitrogen and converting this into ammonia. Microorganisms can convert this into further nitrogen-containing compounds that can be absorbed by the root system. Pretty much all of the world’s ammonia production follows the so-called Haber-Bosch process, where hydrogen gas (H2) and nitrogen gas (N2) react together to form ammonia. The process can be implemented in large, high-yield production lines, but also comes with a major disadvantage: its staggering energy consumption. This is mainly due to two essential steps: producing sufficiently pure hydrogen and nitrogen gasses, and later separating the H2 and N2 molecules into individual atoms. The latter is especially challenging for N2 due to its strong triple bond. To achieve this, factories operate at extreme conditions, with high temperatures (~400 degrees Celsius) and high pressure, largely driven by natural gas. As much as 1.8% of the world’s CO2 emission is caused by factories performing such reactions, consuming around 3-5% of the world’s natural gas production! . Can’t this be done more efficiently? In this case, we strongly suspect so. Certain bacteria are also capable of making ammonia, but in a much more efficient way: without high temperatures or high pressure. It would be extremely valuable to copy this trick. To imitate the bacteria, we need to better understand a particular substance, the FeMo cofactor (short: FeMoco), which acts as a catalytic active site during ammonia production. A perfect simulation of FeMoco is not possible on classical computers, as the structure of roughly 120 strongly reacting electrons rapidly becomes intractable. Researchers from ETH Zurich and Microsoft were the first to recognize that a quantum computer may aid in a more accurate study of FeMoco. A few years later, researchers at Google gave a more concrete prediction: with about 4 million qubits and 4 days of computing time, a single simulation could be accomplished. If we manage, like bacteria, to do this nitrogen fixation at room temperature, this will save a significant percentage of the world’s energy consumption and greenhouse gas emissions. Tom O’Brien, assistant professor at Leiden University and researcher at Google, was quoted that he believes that the simulation of FeMoco is the killer application for quantum computing. And indeed, it rightfully ticks both boxes: there is a significant computational advantage and a meaningful impact on the world. Unfortunately, we need to wait at least until the 2030s before we have a suitably large quantum computer. As a final note, we want to stress that quantum computers do not magically spit out recipes for fertilizers, nor for medicines, batteries, or catalysts. For real breakthroughs, we need a team of chemists, engineers, and other experts, who spend several years to run experiments, have discussions, employ computer simulations, make mistakes, go back to the drawing board a few times, and slowly converge to practical solutions. We should not forget that quantum computers merely provide a new set of tools. The best we can hope for is that smart people will use them in the right way! . ",
    "url": "/part2/chapter_1/#chemistry-a-case-study-of-artificial-fertiliser",
    
    "relUrl": "/part2/chapter_1/#chemistry-a-case-study-of-artificial-fertiliser"
  },"20": {
    "doc": "1 Chemistry, A case study of artificial fertiliser",
    "title": "1 Chemistry, A case study of artificial fertiliser",
    "content": " ",
    "url": "/part2/chapter_1/",
    
    "relUrl": "/part2/chapter_1/"
  },"21": {
    "doc": "2 Quantum networks",
    "title": "Quantum networks",
    "content": "If we’re building computers that deal with qubits, superposition and entanglement, wouldn’t these computers also need some way to send qubits to each other? This is the dream of the quantum internet: a network that exchanges quantum-mechanical photons between devices all around the world, parallel to our well-known ‘classical’ internet.  . There is a bit of a paradox here. On the one hand, a full-blown quantum internet is very, very far away: a network that reliably transports actual qubits is arguably harder to realize than a large quantum computer, as it will build upon the error correction technology that we’re only just figuring out. On the other hand, it is often said that ‘quantum networks’ have a higher Technology Readiness Level than computing. That sounds like a contradiction, right? . The main reason is that there are some applications for ‘imperfect’ quantum networks, in particular in the context of cryptography.  . In that sense, quantum networking applications have always been ‘ahead’ of quantum computing. Already in 1984, long before quantum computers were seriously considered, researchers Benett and Brassard discovered a method to securely negotiate a secret key (think of a password) between two parties, based on sending individual photons. Their result is now famously known as the BB’84 protocol. Similarly, the commercialization of network technologies has long been ahead of computing. Early quantum startups like MagiQ Technologies and ID Quantique were founded around the new millennium, and brought their first commercial networking products to the market in 2003 and 2004. This technology, using a quantum network to establish a secret key between two endpoints, is called Quantum Key Distribution (QKD) – an application that we will address in much more detail below. The promises of the quantum internet . There is a long list of arguments why we should be excited about the quantum internet. Here is a list of the applications that we hear most frequently: . | Clustering quantum computers: By connecting multiple smaller computers, one might build a much larger computer which has more combined memory and can tackle larger problems.  . | Securing your classical communication. The main contender here is Quantum Key Distribution (QKD), sometimes dubbed the “unhackable” network. This allows two distant users to create a secret key (think of a password) that they can later use for further cryptographic applications. | . | “Blind computing”: Encrypting your data while still allowing someone else to process it. What if you hire an Amazon cloud computer to do calculations on your data, but you don’t want Amazon to actually see your data? It turns out that you can make quantum computers do their computations even while keeping data encrypted, with some caveats. Similarly, one could use ‘secret’ software to solve someone else’s problem without them discovering this algorithm. Such applications often go by the name of blind computing or private computing.  . | A scientific (hard!) overview of blind computing applications.  | . | . | Position verification: Can you prove that you are currently at a given location, in a way that cannot be spoofed?  | . | A short introductory video [3:23] | . | Complete protocols that require input from multiple parties, such as leader election or Byzantine agreement. You can find many more in the Quantum Protocol Zoo.  | . | Make quantum sensors more effective. There exist proposals to combine different telescopes or gravitational wave detectors, and plans to synchronize quantum clocks.  . | A scientific (hard!) overview of distributed quantum sensing | . | . Much more about the various applications can be found in this online Quantum Internet magazine by TU Delft, or as listed by the Quantum Internet Alliance. How useful is the quantum internet in practice?  . Admittedly, many applications of the quantum internet will depend on how much we will use quantum computers. If quantum computers become widespread in the future, then communication between them also seems to be extremely worthwhile. On the other hand, our current outlook of quantum computers focuses on special-purpose devices that are used to solve isolated problems. It is not immediately clear why they would benefit from a quantum internet. There is a clear road map to build a reliable quantum internet in the future (involving fascinating tricks like entanglement distillation and teleportation), but this would require multiple error-corrected quantum computers by itself! For that reason, in this guide, we’re not yet looking ahead at applications like clustering computers, multi-party computations, private computing, or making sensors more effective.  Regarding clustered quantum computers, we frequently hear arguments that we can make a ‘bigger’ quantum computer by connecting individual ones. I’m always wondering why those computers are not just simply built next to each other. Connecting those is much, much easier than connecting them over a quantum internet.  . In the foreseeable future, the first interesting applications are those that work over a “noisy” connection, and transport just one qubit at a time (or perhaps a handful of them). For practical interest, Quantum Key Distribution (QKD) is by far the most interesting application.   . The case for QKD . To fully understand QKD, we will need to have a bit more background about cryptography, especially the “key distribution problem”. For a full account, we recommend first reading the chapter on cryptography. In short: we’re wondering how Alice can agree on a secret key with her distant friend Bob, in a world where everyone can read plain data sent over the internet. Surely they can’t just generate a random key and send it over to each other, without having any encryption in the first place! This problem is commonly solved using public key cryptography (which we know will be revamped in the following years). If you really don’t trust public-key cryptography, the main alternative is to physically transport a usb stick by a trusted courier.  . Compared to conventional cryptography, the unique selling point of QKD is that it is fundamentally impossible for cybercriminals to obtain the secret key as it is being distributed. As long as our understanding of quantum mechanics is correct (arguably the most well-test theory in science), no amount of computational power or mathematical breakthroughs will let an attacker gain information about the key. Of course, this assumes that the protocol is executed precisely as prescribed, and there are no other vulnerabilities in the actual hardware or software used.  . This is fundamentally different from today’s approach of public key cryptography, which must rely on certain mathematical assumptions. We know for sure that, with sufficient computational power, these codes can be broken, but we argue that this takes such an incredibly long time that nobody will bother (except for bragging rights and prize money). Still, such statements about computation times are based on assumptions, and our trust is purely based on our experience that no brilliant cryptanalyst has broken it yet. In fact, well-regarded cryptosystems do get broken from time to time, such as SIKE, which was in the race to become a new NIST standard.  . That said, although QKD is “unhackable” in theory, the actual hardware and software are equally likely to contain vulnerabilities. Contrary to well-trusted public-key cryptography, no QKD system has received proper certification and accreditation, and a significant fraction of historical products have been hacked.  . QKD requires specialised hardware — although it is much less demanding than other quantum internet applications we mentioned. It can already prove useful on a basic point-to-point network with just two connected parties, of which one should send photons, and the other receive them. This is orders of magnitude less complex than building a fully-featured internet. Moreover, the qubits need only be sent and measured one at a time: no quantum memory or extensive computation are needed. There have already been several demonstrations that use standard telecom fiber (the stuff that’s already in the ground), or satellite-based systems that communicate through air. QKD hardware is fancy and expensive, but not completely out of reach.  . The major downside of QKD is that it has no way to confirm who the person on the other end of the line is. Some form of authentication is still needed – which is mostly done with secret keys that should already be present in the first place! This makes QKD just a partial solution to the key distribution problem.  .   . Further reading . | A video explanation of QKD for laymen or experts. | Companies like Toshiba and ID Quantique offer commercial QKD systems for distances of around 100 km.  . | Chinese scientists achieve QKD through satellites over 1000 km.  . | Nature commentary why practical long-range QKD is still out of reach.  . | . What do experts say?  . Cryptographers that have been working on securing classical computers are typically sceptical about QKD. In fact, all security authorities that we are aware of will advise against the use of QKD at this current point in time. They find the use of additional, uncertified hardware too large of a security risk, and stress that there is a better solution that works on conventional computers: post-quantum cryptography (PQC). From their perspective, PQC offers all the required functionalities, and is currently more practical to test, certify and implement.  . Be careful not to confuse the abbreviations PQC and QKD. QKD is the stuff that requires a quantum network. PQC is the stuff that runs on classical computers.  . A discussion between physicists and cryptographers. A fair argument in favor of QKD, stems from the ‘harvest now, decrypt later’ attacks that could be done over today’s internet. These would imply that even the privacy of today’s messages is compromised. This could be a convincing reason for organizations to rapidly jump into a first QKD testbed. Still, for those who can risk the expenses, it might be more worthwhile to look at more mature and readily available solutions. For example, there exist certified solutions that rely on symmetric encryption with trusted couriers.  . See also: . | Compumatica offers symmetric encryption with keys transported on SD-cards.   . | TNO designed a ‘quantum-safe proxy’ as add-on to existing cryptography.  . | StackOverflow question: “Why does the NSA find QKD impractical”? . | .   . What’s left is a very niche use-case for the most forward-thinking organizations that deal with extreme security requirements. It is somewhat of a pity that QKD is not so mature yet today, now that many organizations will start their security migrations. A widespread adoption of QKD would make it easier to expand to a large-scale quantum internet in the future. Nevertheless, since a quantum threat could be here as soon as the early 2030s, most companies are recommended to urgently migrate to post-quantum cryptography (PQC) first, and potentially consider QKD as an add-on for additional security later, if needed.  .   . Conclusion . In conclusion, most applications of a quantum internet will not be immediately relevant in the foreseeable future, with an exception for QKD. And even QKD might not be the killer applications that many investors are hoping for – it most definitely shouldn’t be called “unhackable”.  . Still, it seems unfair to us to dismiss a quantum internet because it would be ‘too technologically challenging’ or ‘too expensive’. These arguments are correct today, but perhaps naive on a scale of several decades. Would anyone from the 70’s have believed that today, more than half of the world population is streaming videos on a mobile phone for just a few dollars per month? Who knows what the quantum internet will look like 50 years from now.  . ",
    "url": "/part2/chapter_2/#quantum-networks",
    
    "relUrl": "/part2/chapter_2/#quantum-networks"
  },"22": {
    "doc": "2 Quantum networks",
    "title": "2 Quantum networks",
    "content": " ",
    "url": "/part2/chapter_2/",
    
    "relUrl": "/part2/chapter_2/"
  },"23": {
    "doc": "3 The impact on cybersecurity",
    "title": "The impact on cybersecurity",
    "content": "In the world of quantum computers, the most convincing exponential speedup lies in codebreaking. Anyone who wants to understand the impact of quantum computers, will need to know their basics of cryptography. Let’s start at the beginning.  . Cryptography is much more than just secrecy  . Why do we actually use cryptography? Pretty much everyone will immediately think of: . | Privacy / confidentiality: making sure that others cannot read your data (especially when messages are sent over a network). | . However, there are many more threats that cryptography protects us from. Most people wouldn’t normally worry about them, but when any of the following is missing, cybercriminals can cause a lot of harm:  . | Authentication: You want to verify that a message really came from the entity that claims to send the message. For example, during online banking, you want to be 100% sure that you are communicating with your bank and nobody else. Another example is when installing a new piece of software. When executing the latest Windows update, your computer makes sure to check that there is a ‘digital signature’ that belongs to Microsoft. Imagine how unsafe your computer would be if anyone could send fake updates! | . | Integrity: You want to verify that nobody changed the message during transit. Imagine what damage could be caused when your emails are maliciously altered before they arrive, or when the commands coming from an air traffic control tower are modified. Similarly, any software installer confirms that the software wasn’t changed by anyone but the original publisher, by verifying a digital signature. | . | Establishing secret keys: How do you negotiate a new secret key with a brand new webshop that you never visited before? This is a seemingly impossible task if bare internet traffic can be read by anyone, but modern cryptography has a solution. | . There are some others, like non-repudiation and availability, that we don’t discuss here. Remember the above bold-faced words, as we will come across them a lot more.  . We hope that this introduction makes the reader aware of the enormous importance of proper cryptography, and the sheer number of cryptographic checks that are required for proper functioning of our IT. You would be surprised how often you use cryptography on a daily basis, through your laptop, phone, car keys, or smart cards. The quantum threat is mainly to public-key cryptography.  . A common misconception, which we see a lot in popular literature, is that the quantum threat can be summarised as follows. (Both of the statements below are incorrect!)  . | A quantum computer will break all of today’s cryptography.  . | A quantum internet is needed to keep our cryptography safe again. | .   . To better understand this, let’s first look at what cryptography a quantum computer will break, and which it won’t. Later, we will look at the necessity of a quantum internet.  .   . In line with common cryptography jargon, we will have two parties, Alice and Bob, who want to communicate with each other. We distinguish two different types of cryptography: the symmetric and the asymmetric (public key) variants.  . In symmetric (or private key) cryptography, we assume that both Alice and Bob already know some secret key. This could be a password that they both know, or more commonly, a very long number represented by (say) 128 bits in their computer memory. Alice can use the key to encrypt any message using a protocol like AES. Bob can then use the same key to decrypt this message. The details of how encryption and decryption work are unimportant for our purposes. The only thing that’s relevant is that our computers can do this very efficiently, and that it’s considered extremely safe (without the key, nobody could reasonably break this encryption).  . In asymmetric cryptography, or more often called public-key cryptography (PKC), each participant has two keys: a public key and a private key. The public key can be shared with anyone, while the private key must be kept secret. That’s why we use the suggestive colours green (save to share) and red (be careful!). If Alice wants to send an encrypted message to Bob, she uses Bob’s public key to encrypt the message. If Bob wants to decrypt the message, he uses his private key.  . The setting with two keys offers more functionality. For example, using the previous encryption method, Alice could send a secret key to Bob, which they can then use for symmetric cryptography (which is often a lot faster). Furthermore, the protocol works in ‘reverse’. Alice can use her private key to encrypt a message, which then anyone in the world (including Bob) can decrypt using the corresponding public key. Bob should then be confident that Alice is the only person in the world who could have encrypted this message (indeed, something encrypted with the private key can only be decrypted with the public key, and vice versa). This forms the basis of digital signatures.   .   . This is precisely what’s used whenever you open a webpage. Your browser (here: Chrome) will display that the connection is secure, which means that (amongst others) it verified that the digital signature is valid. This ensures authenticity and integrity.  . It should come somewhat as a surprise that public-key cryptography is even possible at all! It’s kind of a small wonder that encryption and decryption with two totally different keys can be made to work, thanks to some powerful mathematics. (I don’t know of any physical locks that work this way). However, it turns out that the delicate relationship between the two keys is also a weak spot… . How good are quantum computers at cracking cryptography?  . In principle, symmetric-key cryptography is fairly safe against quantum hackers. The biggest problems are brute-force attacks, where an attacker effectively tries every possible secret key. Using a key of 128 bits, the total number of possible keys is 2128 — that’s an incomprehensibly large number (much more than the number of atoms in a human).  . We know that Grover’s algorithm speeds up brute-force search, by reducing the number of attempts from 2128 to its square root, which is 264. This is something that cryptographers are not happy about, but considering the slowness and extra overhead that comes with quantum computers, this doesn’t seem to be a problem in the foreseeable future. Still, to be on the safe side, it is recommended to double key lengths, hence to use the same algorithm with 256-bit keys. Changing this in existing IT infrastructure is relatively straightforward, although one shouldn’t underestimate the time and costs for such changes within large organisations. The situation is completely different with public-key cryptography. The most-used algorithms today, RSA and ECC, can be straightforwardly broken by a large quantum computer. We discussed the details of  Shor’s algorithm earlier. (To be precise: today’s best results estimate that 20 million qubits and around 8 hours are needed). Luckily, there exist PKC systems that are believed to be safe against quantum computers, and an obvious way forward is to start using these. We call such systems post-quantum cryptography, and despite the confusing name, they’re built to work on conventional computers. We discuss the rabbit hole of migrating to new cryptography in a different chapter, and similarly for estimating how many years we still have until a quantum computer can attack RSA and ECC.  . There is another threat that everyone should be aware of, called harvest now, decrypt later. Encrypted messages that are sent over a network today can be intercepted and stored for many years, until a quantum computer can efficiently decrypt the messages. In practice, we use public-key encryption mainly to establish temporary secret keys to be used with symmetric-key cryptography, but even these can, in principle, be found retroactively. In other words: the confidentiality of today’s communication is already threatened!  . Further reading: . | Redhat blog on Mosca’s theorem, which states when you should start upgrading if your communication needs to remain secret for at least X years. | .   . The following table summarizes how our cryptosystems are threatened: . |   | Symmetric | Public-key | . |   | Today (AES, … ) | Today (RSA, ECC) | PQC                       | . | Against classical computers | Safe | Safe | Safe | . | Against quantum computers | Safe* . *with double key lengths . | Unsafe | Safe | . ** Why don’t we switch to symmetric cryptography? ** . Public-key cryptography solves a very fundamental problem: how can Alice and Bob agree on a secret key before they have a means of encryption in the first place? They cannot just send a new key over the internet without any form of encryption, because anyone would be able to read this. This is the fundamental problem of key distribution. Let us look at the functionality offered by the two types of cryptography:  . |   | Symmetric | Public-key                    | . | Confidentiality (privacy) | Only with pre-shared keys | ✔ | . | Authentication / Integrity   | Only with pre-shared keys | ✔ | . | Establishing secret keys | ✗ | ✔ | . If only we could somehow give Alice and Bob pre-shared keys in a secure way, we would resolve most of these problems. Without public-key cryptography, there are other options: . | Alice and Bob could meet every other week to exchange USB drives with secret codes. | Alice and Bob could both trust a large “key server”. If both share a secret key with the key server, they can securely ask the server to generate a new secret key that they can use together.  . | . Still, none of these form an attractive alternative to public-key cryptography, especially if one considers the sheer number integrity and authenticity checks we perform every day, and the incredible number of online entities we potentially want to communicate with.  . What solutions exist? . TODO: More on PQC, hopefully when new standards are released! . What about Quantum Key Distribution (QKD)? . As we saw in a different chapter, Quantum Key Distribution partially solves the key distribution problem. It requires a quantum network connection between Alice and Bob, and somewhat expensive quantum devices to generate and measure photons. When used, Alice and Bob will obtain a secret key (that can be as long as they like), in a very safe way (in the sense that nobody listening in on their classical or quantum communication can possibly find this key). Unlike PKC, this method still requires pre-shared keys for authentication (because otherwise you can’t be sure with whom you will share your new secret key). Therefore, it won’t completely solve the key distribution problem.  . There is even more reason to be careful: many security authorities warn against adopting QKD today. Although the theory is very sound, today’s hardware is still in an early stage. The time to generate secret keys is still relatively long, and it is very likely that the actual software and hardware contain mistakes that make them vulnerable to attacks.  . It is somewhat of a pity that QKD is not so mature yet, because it would be a viable weapon against Harvest Now, Decrypt Later (since harvesting the pre-shared authentication keys is not a problem). Moreover, widespread adoption of QKD would make it easier to expand to a large-scale quantum internet. Nevertheless, since a quantum threat could be here as soon as the early 2030s, most companies are recommended to urgently fix their post-quantum cryptography (PQC) first, and potentially consider QKD as an add-on for additional security later, if needed.  .   . What about Quantum Random Number Generators (QRNG)? . Good random number generators are extremely important in cryptography, and QRNGs could provide a good alternative to the hardware random number generators that are widely used today.  . However, all they do is generate random numbers – that doesn’t make any protocol safe in itself. As a general warning: **products with ‘quantum’ in the name do not automatically protect against Shor’s algorithm!  ** . What steps should a typical company or government take?  . We dedicate a separate chapter to that!  . Conclusion . It should be clear that cryptography is strongly intertwined with quantum computing, through Grover’s algorithm, Shor’s algorithm, and Quantum Key Distribution. Nevertheless, security experts recommend that there is an obvious way forward: . | Replace current public-key cryptography with new, quantum-safe protocols (PQC). | Double key lengths in symmetric cryptography.  . | . Especially the first bullet is a major challenge. There are many legacy systems around on the internet that may not be updated so easily. There are billions of devices that are all interconnected, so updating one device will surely cause incompatibilities somewhere else. What’s more, PQC protocols will surely require more CPU power and more memory than today’s trusted methods. Companies may need to update the core code of hundreds or even thousands of applications. And lastly, the new protocols haven’t been tested as extensively as our conventional methods, so it is not unlikely that new security issues will be found. Quantum computers, before they are even built, are already destined to make the next decade an incredibly complex period for anyone who deals with cryptography!  . ",
    "url": "/part2/chapter_3/#the-impact-on-cybersecurity",
    
    "relUrl": "/part2/chapter_3/#the-impact-on-cybersecurity"
  },"24": {
    "doc": "3 The impact on cybersecurity",
    "title": "3 The impact on cybersecurity",
    "content": " ",
    "url": "/part2/chapter_3/",
    
    "relUrl": "/part2/chapter_3/"
  },"25": {
    "doc": "4 Optimization and Machine Learning, What do current players do?",
    "title": "Optimization and Machine Learning: What do current players do?",
    "content": "TODO: write section! . Where should we look for a killer application? . Well, we simply don’t know! However, some useful technical hints may be: . | As described above, we’d most likely require an exponential or some heuristic speedup. This is much more likely achieved on problems where we don’t already know very efficient classical algorithms.  . | When reading data is a limiting factor (as in “big data” applications), quantum computers appear to be very slow. Getting the data into a quantum computer seems to take at least as long as processing the data on a much cheaper supercomputer. This holds, for example, when searching through a database, but also for data-intensive simulations like weather forecasting.  . | Similarly, if the desired output is a large amount of data (such as a very large list or table), then a quantum computer is likely not efficient. Most quantum algorithms look at a global property of a function or dataset that can be encoded in a very small output (like Deutsch-Jozsa or Shor’s algorithm when interpreted as finding the period of a function).  . | Some people would say that if quantum computers are not “faster”, perhaps they might solve a problem “more accurately” (for example, they might produce a more reliable forecast). However, when we look at speedups, then accuracy is already taken into account: we compare the number of steps asserting the output has a given accuracy.  . | Classical computers are already incredibly fast, and the bottleneck for many real-world computational problems is not in a computer’s speed. If an application does require a supercomputer today, then it’s unlikely that anyone will invest in a quantum computer soon. | . ",
    "url": "/part2/chapter_4/#optimization-and-machine-learning-what-do-current-players-do",
    
    "relUrl": "/part2/chapter_4/#optimization-and-machine-learning-what-do-current-players-do"
  },"26": {
    "doc": "4 Optimization and Machine Learning, What do current players do?",
    "title": "4 Optimization and Machine Learning, What do current players do?",
    "content": " ",
    "url": "/part2/chapter_4/",
    
    "relUrl": "/part2/chapter_4/"
  },"27": {
    "doc": "1 Quantum hardware",
    "title": "Quantum hardware",
    "content": "Conventional computer hardware is extremely well standardized. No matter what supplier you buy a computer from, you can be reasonably sure that you can run your favourite applications on them. We expect to have professional servers to run non-stop for years without the hardware ever failing. Thanks to such high reliability and clear compatibility, it is rather easy to compare different machines, by looking at speed (e.g. floating-point operations per second, FLOPS) and memory size. We will see that this is radically different for quantum computers: devices make mistakes, have limited functionalities, and depending on your application, you might like to use a completely different architecture. In this chapter, we take a high-level business perspective at quantum computing hardware. What should you know when starting your quantum journey?  . Different functionalities . The figure below shows different types of functionalities that quantum computers can have (top, brown), along with some examples of hardware that is available (below, yellow). This list is by no means complete! It should at best give an impression of the current state of the art. Let us start by taking a closer look at the functionalities. Our biggest dream is to have a ‘universal quantum computer’. The word ‘universal’ indicates that it is capable of executing any quantum algorithm (or technically: to approximate any algorithm’s output to arbitrary precision). For comparison: your laptop, phone, and even a smartwatch are universal classical computers, making them capable of running any classical application you can think of: spreadsheets, 3D games, data encryption, and so on. Similarly, a proper universal quantum computer is suitable for any quantum application, regardless of whether it is known today or invented in the future.  . The definition of ‘universal’ is blind to some details such as memory limitations (it assumes you will never run out of RAM), and omits tedious details about software compatibility (a Playstation game won’t run on an XBox). In our high level overview, such details are unimportant: the main point is that there also exist devices that can not run just any algorithm. Does a universal computer need to be “gate-based”? . No matter what architecture or qubit type you pick, our current technology will not allow you to run very long computations. This is due to the inherent imperfections in construction and control of quantum devices. The imperfections cause errors to accumulate during a computation, so that after some number of steps, the result is almost surely corrupted and unusable. For longer computations, it is essential to fix errors on the fly, using so-called error correction (also known as: fault-tolerance).   . Today, we are stuck in a so-called NISQ-era, with Noisy Intermediate-Scale Quantum devices. Many are in principle universal, except that they are limited both in the number of qubits, and in the number of steps that can be executed. Companies like IBM, IonQ, Quantinuum and Pasqal all have NISQ computers available to test your own programs on.  . Making a universal computer is challenging, and engineers can make special-purpose devices that improve in certain areas (like number of qubits or clock speed) by omitting certain functionalities. In a Quantum Simulator, the computer specialises in simulating a certain class of materials or molecules. The precise capabilities are often captured in a Hamiltonian that specifies which materials qualify. As an example, Harvard-spinoff QuEra has a quantum simulator available over the cloud that mimics a quantum Ising model. Today’s simulators (like QuEra’s) are fairly close to a universal computer (lacking only a few technical ingredients) and are similarly subject to accumulating errors. However, they are not designed to run conventional (gate-based) algorithms. There might be some confusion in jargon here, as the term ‘quantum simulation’ is also sometimes used when a classical computer tries to mimic the behaviour of a quantum computer. Others use the term ‘emulation’ for such classical approaches.  . See also: . | QuEra announces a 256 qubit simulator available over the Cloud.  . | Pasqal performs a material science simulation with 196 qubits and sells 100-qubit simulator in a EuroHPC tender. | . Another special-purpose device is the Quantum Annealer, for which the Canadian scale-up D-Wave is especially well known. These special-purpose devices can solve a certain class of optimization problems that goes by the name of QUBO: quadratic unconstrained binary optimization. There is a well-developed theory of mapping various problems into the QUBO formalism, making annealers fairly versatile machines. However, quantum annealers will never be able to take advantage of the various other quantum algorithms out there: even with enough qubits, we don’t see them cracking codes with Shor’s algorithm.  . See also: . | D-Wave’s introduction to its quantum annealing platform | . Different building blocks . There is another question about what material the qubits are actually made of. Scientists have cooked up several competing approaches, such as superconducting materials, photons, or individual atoms, or ions, each with their own strong and weak spots. The methodology or material used to make a physical qubit is often called the qubit implementation, the qubit type, or (we prefer) qubit platform.  . For conventional computer electronics, we converged to a single choice of material and broadly a single manufacturing process, based on silicon wafers and lithography. For quantum computers, there is still a fierce race between the different platforms, and it is totally unclear which will eventually be the winner — or whether we will converge to a single winner at all.  . There is an interesting story behind the different hardware types, but we won’t delve into that in this non-technical guide (would you otherwise care what material your classical CPU is made of?). However, anyone who wants to test quantum programs on actual hardware should definitely know the details. Interested readers can start here: . Further reading: . | Different types of qubits explained by Sifted.eu . | Different types of qubits at IQC Waterloo . | Different types of qubits on Wikipedia . | A MOOC about different hardware types by TU Delft . | . It is interesting to note that all these different machines (universal, annealers, simulators) can in principle be built using any type of qubit. If you go back to the figure at the top, you can see that there exist different qubit types with different functionalities. It’s not unthinkable that the empty squares will also be filled, so that we have access to superconducting-based simulators, or annealers that use ultracold atom qubits (or perhaps the authors have missed this!). In fact, we have already seen many academic showcases of superconducting simulators in academic literature. TODO: ADD OVERVIEW TABLE OF WHAT SUPPLIERS HAVE. ",
    "url": "/part3/chapter_1/#quantum-hardware",
    
    "relUrl": "/part3/chapter_1/#quantum-hardware"
  },"28": {
    "doc": "1 Quantum hardware",
    "title": "1 Quantum hardware",
    "content": " ",
    "url": "/part3/chapter_1/",
    
    "relUrl": "/part3/chapter_1/"
  },"29": {
    "doc": "2 Error correction",
    "title": "Error correction",
    "content": "At a glance . | To run long computations, we need to dramatically reduce the likelihood of error of each elementary step – not just a little bit, but by a factor of millions.  . | Error correction is the most effective method to achieve extremely low error probabilities. It combines a small number of ‘physical’ qubits (think of several hundreds) into a single ‘logical’ qubit that suppresses errors exponentially.  . | Logical qubits are still not perfect qubits: the ‘number of steps’ that they can survive is an important specification that determines whether they can run your application. | . The recently announced roadmap by QuEra caused quite a buzz: the startup presents its plans in terms of logical qubits, aiming to have 100 of these by 2026. This is a significant shift from their earlier focus on physical qubits. Experts agree that achieving error correction is one of the key milestones towards large-scale computations, like breaking cryptography. As we expect many breakthroughs in error correction in the years to come, this is the right time to understand the importance of error correction and clear up some misconceptions about logical qubits. A statement that we often hear is the following (which is incorrect!) . “Logical qubits (or: error-corrected qubits) are resilient to errors that occur during a computation. Once we have logical qubits, we can increase the length of our computations indefinitely. “ . What’s the problem here? Well, not every logical qubit is created equally. We expect to soon see logical qubits that are perhaps 2x more accurate than today’s bare hardware qubits, and later 10x, and in the future perhaps 1000x. Error correction is a trick to reduce the probability of errors, but it will not eliminate errors completely. In the following decade, we expect to see gradual improvements, hopefully down to error rates of 10-10 and below. Let’s explore the reasons behind this. What is error correction? . In quantum error correction, we combine some number (think of hundreds or thousands) of ‘physical’ hardware qubits into a virtual ‘logical’ qubit. The logical qubits are the information carriers used in an algorithm or application. Error correction methods can detect whenever tiny errors occur in the logical qubit, which can then be ‘repaired’ with straightforward operations. Under the assumption that the probability of hardware errors is sufficiently low (below a certain error threshold), the overall accuracy improves exponentially when we combine more physical qubits per logical qubit. Hence, we obtain a very favourable trade-off between the number of qubits, and the accuracy of the qubits. Doesn’t measuring a quantum state destroy the information in the qubits? . Indeed, if we naively measure all the physical qubits, then that would destroy the computation. However, quantum error correction uses an ingenious way to measure only whether or not an error occurred. It learns nothing about the actual information content of the qubit. It turns out that this way, the data stored in the logical qubit is not affected.  . Why are errors so much of a problem? How do errors screw up our computations?  . In short: even tiny errors are a problem because we want to perform incredible numbers of quantum operations — think of billions or trillions of them.  . Let’s make this more concrete. A computer program is essentially a sequence of ‘steps’, each of which a computer knows how to perform. We say that a program or algorithm has a width, which is the number of qubits it requires. It also has a depth, which is the number of consecutive steps that need to be performed. In early hardware, you may interpret one step as a single quantum gate.  . The concept of  ‘width’ is pretty straightforward: if the computer doesn’t have enough memory, it will not be able to run the program. Dealing with ‘depths’ is harder. According to the laws of statistics, to run a program of 109 steps, we need to limit errors to roughly the inverse: say, 10-9 per step. If the error is larger, it becomes extremely unlikely to find a correct outcome of the computation. These are not hard numbers: a computer with 10-10 error would be a significant improvement (resulting in much fewer mistakes), and a computer with 10-8 error might be pushed to also find the correct answer after many tries. However, as the imbalance between depth and error grows, the probability to find a correct outcome is reduced exponentially. We illustrate this in more detail in the box below.  . ** . To illustrate, why do we need such small error rates?** . Let’s look at a very simple model of a computer, which is not unlike what happens inside a quantum computer or a modern (classical) CPU. As above, the computer is supposed to work through a list of instructions. We can consider various specifications of a computer: .   . | The available memory, measured in bits (or perhaps megabytes or gigabytes, if you like).  | . | The speed at which the computer operates, measured in steps per second.  . | The “probability of error”, the chance for each computational step to introduce some mistake. This is given as a number between 0 and 1 (or a percentage between 0 and 100%). Many sources use the word ‘fidelity’ instead, which can be roughly interpreted as the opposite (fidelity ≈ 1 – probability of error). In this text, we sometimes just say “error”. | .   . In this simple model, the time taken to complete the computation equals: “depth” x “speed”. You can make a computer program faster by increasing the speed of the computer, or by writing a ‘better’ program that takes fewer steps.  . The influence of errors is harder to track. For contemporary computers, we typically don’t worry about hardware mistakes at all: every step has essentially 100% certainty to output the correct result. Unfortunately, in our little model, this is not the case.  . Assume that each step has a 1% (= 10-2) chance of error. What will the impact on the final computation be? Here, we compute the chance to finish the computation without any errors, for various numbers of total steps:  . | Error probability: 1% |   | . | Number of steps | P(success)   | . | 1  | ( 0.99 )1 = 99% | . | 100 | ( 0.99 )100 = 37% | . | 1000 | ( 0.99 )1000 = 0.004 % | . | 10,000 | ( 0.99 )10,000 =   10-44  | . In this simple model, we assume that any error is catastrophic. This is quite accurate for most programs. You might argue that there is a miniscule chance that two errors cancel, or that the error has very little effect on the final result, but it turns out that such effects are statistically irrelevant in large computations.  . Now, assume we improve our hardware, towards an error rate of 0.1% (=10-3), then we find: . | Error probability: 0.1% |   | . | Number of steps | P(success)   | . | 1  | ( 0.999 )1 = 99.9% | . | 100 | ( 0.999 )10 = 90% | . | 1000 | ( 0.999 )1000 = 37% | . | 10,000 | ( 0.999 )10,000 = 0.004  | . A probability to succeed of 37% sounds bad, but for truly high-end computations we might actually be okay with that. If the program results in a recipe for a brand-new medicine, or if it tells us the perfect design for an aeroplane wing, then surely we don’t mind repeating the computation 10 or 100 times, after which we’re very likely to learn this breakthrough result. On the other hand, if the probability of success is 10-44, then we will never find the right result, even if the computer repeats the program billions of times.  . In the table above, we see a pattern: to reasonably perform 102 steps, we require errors of roughly 10-2 or better. To perform 103 steps, we need roughly a 10-3 chance of error. These are very rough order-of-magnitude estimates, but they have a very useful conclusion when dealing with very large circuits (or very small errors): if you want to execute 10n steps, you’d better make sure that your error probability is not much bigger than 10-n.  . This simplified model assumes that an operation either works correctly, or it fails, but nothing in between. In reality, quantum operations act on continuous parameters, and therefore they have an inherent, scalar-value accuracy. For example: a quantum gate might change a parameter from A to A+0.49, where it’s supposed to do A+0.5. For our discussion, this doesn’t really matter — for our qualitative conclusions, it suffices to see a “99% accurate” quantum gate as simply having a 99% chance of succeeding. We also overlook various other technical details, operations carried out in parallel, different types of errors, native gate sets, connectivity, and so forth — these make the story much more complicated, but will not change our qualitative conclusions. Why don’t we just make the hardware more stable? . To some degree, we can still greatly reduce errors by creating more accurate hardware. However, quantum objects are so incredibly fragile that even getting down to 10-2 errors requires some of the world’s most astonishing engineering. We definitely hope to see two-qubit gate errors reduced to 10-3 and perhaps even 10-4, but achieving targets of 10-9 seems unlikely with incremental hardware engineering alone. On the other hand, quantum error correction is incredibly effective: the error drops dramatically at the cost of adding a modest number of qubits, which are assumed to be scalable anyway. That’s why experts agree that error correction is the right way forward.   . Do we use error correction in classical computers too? . This might be a good moment to appreciate the incredible perfection of classical computer chips: while doing billions of steps per second, running for months in a row, sometimes with thousands of cores at a time, errors in CPUs practically never occur. I was hoping to find hard numbers on this, but companies like Intel and AMD seem to keep this under stringent non-disclosure agreements. However, some research shows that errors under 10-20 are easily attained as long as we don’t push processors to their limits (in terms of voltages and clock speeds). Memory (RAM) does often come with error correction for high-performance supercomputers, and some form of CPU error correction was sometimes used in older mainframes and (even today) in space probes.  . Longer computations need more qubits . As problems become ‘more complex’, they typically require more from our computers: both in terms of width (number of bits) and depth (number of steps). We could illustrate this as below. You can think of a number “N” as the difficulty or the size of the problem: for example, we might consider the problem of “factoring a number that can be written down using at most N bits”).  . Keep in mind: we’re talking about the requirements to solve a problem here, so that width indicates logical bits. If a computer does not have error correction, then 1 logical bit is simply the same as 1 physical bit – or its quantum equivalent.  . For ‘perfect’ classical computers, the situation is straightforward: if a problem gets bigger, then we need more memory, and we need to wait longer before we obtain the result. For (quantum) computers that make errors, the situation is more complex. With increasing depth, not only do we need to wait longer, we also need to lower the error probabilities, and hence, need more advanced error correction.  . Let’s consider two computers for which we show the width and depth that they can handle (where the available ‘depth’ is essentially 1 / probability of error). On the left is a computer without error correction (hence it has a small, fixed depth). The other is an error-corrected computer that can trade between depth and width (in certain discrete steps).  . The computer without error correction might have enough memory to solve a problem, but often lacks the depth. Even an error-corrected computer might not have a suitable trade-off to solve the hardest problems. Looking at the above example, it seems that both computers can solve the N=10 problem. Here, only the error-corrected computer can solve the N=20 problem, as depicted below. For the N=40 problem, the error-corrected computer might have sufficient depth OR sufficient width, but it doesn’t have both at the same time. Hence, neither computer solves the N=40 problem.  . Towards cracking the N=40 problem, our best bet is to upgrade the error-corrected computer to have more physical qubits. Using error-correction, these can then be traded to achieve sufficient depth (whilst also reserving just enough logical qubits to run the algorithm).  . We have found an interesting conclusion here. Larger problems not only require more memory (to store the calculation), but also more depth, which requires more qubits again! To summarise:  . ‘Harder’ problems -&gt; More depth -&gt; Better error correction -&gt; More physical qubits  . Effectively, once we reach an era of error correction, then increasing the number of physical qubits will still be among the top of our wishlist.  . Further reading: . | Craig Gidney (Google) has a more technical blog post on why adding physical qubits will remain relevant in the following decades.  . | [Technical!] Some scientific work speaks of ‘early fault-tolerant’ quantum computing, such as: . | “Early Fault-Tolerant Quantum Computing”, discussing how we can squeeze as much as possible out of limited devices. | “Assessing the Benefits and Risks of Quantum Computers” takes a similar width x depth approach as we do here, but uses it to assess what applications will be within reach first. | . | . [Technical] What is the current state-of-the-art? . As of January 2024, there have been several demonstrations of error correction (and the slightly less demanding cousin: error detection), but these have all been with limited numbers of qubits, and with very limited benefit to depth (if any at all). However, we seem to be at a stage where hardware is sufficiently mature that we can start exploring early error correction.  . Below are the three most popular approaches to error correction. Each of them can be considered a ‘family’ of different methods, based on similar ideas: . | Surface codes . | Color codes . | Low-Density Parity Check (LPDC) codes . | .   . The surface code (or toric code) has received a lot of scientific attention, as this seems to be on the roadmap of large tech companies like Google and IBM. Their superconducting qubits cannot interact with each other over long distances, and the surface code can deal with this limitation. Many estimates that we use in this Guide (such as the resources required to break RSA or to simulate FeMoco) are based on this code. It has already been tested experimentally on relatively small systems: . | A team from Hefei/Shanghai experiments with a 17-qubit surface code. | Google sees improvements when scaling the surface code from 17 to 49 qubits. | . Color codes are somewhat similar to surface code, but typically lack the property that only neighbouring qubits have to interact. This makes them less interesting for superconducting or spin qubits, but still they appear to work extremely well for trapped ions and ultracold atoms.  . | Startup QuEra demonstrates 48 logical qubits using a color code [Scientific presentation]  . | Already in 2014, an early experiment on a single logical qubit (color code) was performed in Innsbruck. | . LDPC codes are now rapidly gaining attention. They build on a large body of classical knowledge, and could have (theoretically) more favourable scaling properties over the surface code.  . | French startup Alice &amp; Bob are aiming for a unique combination of ‘cat qubits’ together with LDPC codes, which can theoretically match very elegantly.  | .   . Which code will eventually become the standard (if any), is still completely open.  . See also: . | The Quantum Threat Timeline Report asked several experts what they find the most likely approach to fault tolerance (section 4.5).  | .   . What are the main challenges? . Firstly, we would need just slightly more accurate hardware. We mentioned a certain accuracy threshold earlier: state-of-the-art hardware seems to be close to this threshold, but not comfortably over it. Secondly, error correction also requires significant classical computing power, which needs to solve a fairly complex ‘decoding’ problem within extremely small time bounds (within just a few clock cycles of a modern CPU). Classical decoding needs to become more mature, both at the hardware and the software level. It is not unlikely that purpose-built hardware will need to be developed, which for some platforms might be placed inside a cryogenic environment (placing stringent bounds on heat dissipation). Theoretical breakthroughs can still reduce the requirements of classical processing.  . Lastly, it turns out that ‘mid-circuit measurements’ are technically challenging: most experiments so far relied on destructively measuring all qubits at the end of an experiment. Without intermediate measurements, one might retroactively detect errors, but one cannot repair them. We should also warn that many related terms such as “error mitigation” and “error suppression” exist. They might be useful for incremental fidelity improvements, but they don’t facilitate an exponential increase in depth like proper error correction does.  . See also: . | British startup Riverlane builts a hardware chip that ‘decodes’ which error occurred on logical qubits. (Technical report).  | . Conclusion . The bottom line is that one shouldn’t blindly take ‘logical qubits’ as perfect building blocks that will run indefinitely. A logical qubit is no guarantee that a computer has any capabilities, it merely indicates that some kind of error correction is applied (and it doesn’t say anything about whether this error correction works well at all). A much more interesting metric is the probability of error in a single step (in jargon: the fidelity of an operation), which gives a reasonable indication of the number of steps that a device can handle! . ",
    "url": "/part3/chapter_2/#error-correction",
    
    "relUrl": "/part3/chapter_2/#error-correction"
  },"30": {
    "doc": "2 Error correction",
    "title": "2 Error correction",
    "content": " ",
    "url": "/part3/chapter_2/",
    
    "relUrl": "/part3/chapter_2/"
  },"31": {
    "doc": "3 How to read hyped reports",
    "title": "How to read hyped reports",
    "content": "TODO still write this article? . ",
    "url": "/part3/chapter_3/#how-to-read-hyped-reports",
    
    "relUrl": "/part3/chapter_3/#how-to-read-hyped-reports"
  },"32": {
    "doc": "3 How to read hyped reports",
    "title": "3 How to read hyped reports",
    "content": " ",
    "url": "/part3/chapter_3/",
    
    "relUrl": "/part3/chapter_3/"
  },"33": {
    "doc": "4 What steps should your organization take?",
    "title": "What steps should your organization take?",
    "content": "In the previous parts, we discussed the use-cases, the threats, and the timelines of quantum technologies. We will now take a more strategic perspective: what concrete steps can we take today? How does one establish a successful road map? Details will greatly differ per organisation and per sector, but as we are in an early phase, we expect that most enterprises will take surprisingly similar approaches during the next couple of years.  . Several organisations (especially consultants that would love to support you) have extensive writings on how to get started. Some examples: . | Capgemini – Quantum technologies: How to prepare your organization for a quantum advantage now . | McKinsey – Quantum computing use cases are getting real—what you need to know . | BCG – Quantum Computing Is Becoming Business Ready  . | . We find most of these somewhat ‘hypey’, with a strong emphasis on the risks of missing out and the need to take actions quickly. However, they all mention reasonable strategic steps that organisation can take, which we will lay out below. Let’s break them up into 3 different stages: . 1. Start with no-regret moves . Most companies start with early steps aimed at better understanding the situation. These can be done with very little financial risk. Some must-do actions: . | Appoint a quantum lead, or a quantum working group . | Read up and learn. If you’ve come this far in this Guide, you’re already doing a fantastic job.  . | Create internal awareness . | . Optionally: . | Put quantum on the agenda with senior management.  . | Involve collaborators, suppliers and vendors, make your interest in quantum known. It is in your benefit if suppliers are well-prepared.  . | Participate in a workshop, hackathon, and other events. | . We have a list of interesting learning resources, and an overview of Netherlands-based education opportunities and events.  . Very soon, the quantum journey will split into two fairly different categories: .   . | Preparing for quantum applications, where the goal is to leverage quantum technologies to gain some competitive advantage (for example, by strengthening your R&amp;D, further optimising your logistics, improving a product, etc). For most companies, the main items of interest are the applications of quantum computing.  . | Migrating to quantum-safe cryptography, where the goal is to keep your IT secure against attackers with a quantum computer. | . It is important to make this distinction, because these categories have different goals and are conventionally addressed by different departments. Let us first look at quantum applications. Prepare to use quantum applications . 2a: Start exploring use-cases . For most businesses, the goal of early, low-regret moves is to be ready to leverage quantum technologies fairly soon after they start offering an advantage.  . Must do: . | Find the most impactful use-cases in your area. | Sketch a road map for the coming years.  . | . Optional but recommended:  . | Start concrete explorations, for example by testing and implementing trial use-cases. It is relatively easy (and fun!) to follow the tutorial of programming packages like Qiskit or Cirq.  . | Find a partner. Save costs by collaborating on early, pre-competitive exploration.  . | Create PR! We notice that many companies are very actively promoting their early results on quantum applications, even if these do not offer significant advantages yet.  . | Build a skilled workforce. BCG states: “The biggest challenge may be talent, given the supply constraints. […] Building in-house talent will take time, so it is best to start as soon as possible. | . A good exercise is to look at your current needs in high-performance computing. What do you currently spend your computing budgets on? Are there any areas where new tools in computation or modelling could provide serious business value (for example, by being faster, tackling bigger problems, or delivering higher accuracy)? Which quantities would you ideally have calculated, but are beyond the reach of current computers?  . Sometimes you rapidly identify use-cases that are not worth further addressing. For example, if today’s computational power is easily sufficient to meet your needs, it’s unlikely that you want to invest in quantum computing for that use case.  .   . **R&amp;D partnerships **At Quantum.Amsterdam, we have strong ties to Amsterdam-based research organisations. Offers you might be interested in include: . | Short-term applied research by the Quantum Application Lab, which could lead to a roadmap or a proof-of-concept implementation.  . | We invite collaborators to sponsor a PhD or Postdoc researcher at an academic institute, leading to a 2-4 year intensive investigation of a certain use case. There are often subsidies for such public-private partnerships. Our website shows several examples of the past collaborations, and information about starting a new project can be found at the local tech transfer office.  . | . Also see: . | Quantum.Amsterdam meetup   (Youtube) | . 3a: Implementing actual applications, whenever ready . From here onwards, we find it hard to give concrete advice: goals may depend on your area of business, and on the way that the field of quantum will progress. Other sources will simply tell you do “develop a long-term strategy” or similar.  . For inspiration, or a dot on the horizon, you may think towards a competence center for quantum computing, similar to how many companies have special departments for data science and/or AI. It may also be reasonable to combine these departments.  . A common advice that we will relay here: the business use of quantum computers is still very uncertain, so at best we can recommend to remain agile! . Migrating to post-quantum cryptography . 2b. Prepare for migration to post-quantum cryptography.  . Cryptography is a completely different beast, with a more concrete goal, and more urgent timelines for most organizations (here’s why). Luckily, pretty much everyone faces the same problem, making it easier to give concrete guidelines. In essence, anyone who uses modern cryptography should migrate to Post-Quantum Cryptography (PQC) in the next decade. Although standards and regulations are still under construction, there are some urgent steps should be taken well before the migration can start.  . We recommend the PQC Migration Handbook (April 2023), written by the Dutch secret service AIVD, and research organisations CWI and TNO.  . In general, as a first step, it recommends to: . | Determine the risk and urgency of PQC migration. This likely requires making an inventory of all cryptography in use, and determining how long your data should remain private.  . | Create a migration plan.  . | . “Certain organisations should already start working on mitigating measures now. [..] For instance, organisations handling data that will still be confidential 20 years from now, or organisations developing long-lived systems that will still be in use decades from now.” . THE PQC MIGRATION HANDBOOK . Judging from previous migrations, [implementing PQC] might take well over five years. THE PQC MIGRATION HANDBOOK . 3b. Migrate . This is a much more technical part, for which you will need a well prepared migration plan. We find it likely that quantum computers might break today’s RSA encryption standard somewhere in the 2030’s, so we stress that such migration should be completed well before that time — taking in to account that IT migrations can take significantly longer than originally planned! . FAQ . Should I have knowledge of quantum mechanics? Should I understand quantum hardware?  . When you are tasked with implementing early-stage quantum applications: then yes! . As a strategic manager, or when working on post-quantum cryptography: no.  . Do I really need to work on NISQ? . That’s a good question that is hard to answer. We find it unlikely that near-term quantum computers (in the next, say, 1-4 years) will create relevant advantages, although there are plenty of experts who are more optimistic. Future applications will likely differ strongly from the way we ‘program’ quantum computers today, but practising on today’s hardware can grow your understanding and give an edge in experience.  . What should I do first: focus on quantum applications or post-quantum cryptography? . For most organisations, the threat to security is more urgent, especially because the migration trajectory can take several years (and this must be completed well before we have large-scale quantum computers!).  . However, most organisations work on both trajectories in parallel. I’m looking for a collaboration – what should I do? . Typically, business developers meet each other at conferences and events, where you may find like-minded partners. We also encourage you to contact us for some sparring on what your organization can do, and to get connected to Netherlands-based knowledge institutes like QuSoft and Quantum Application Lab.  . ",
    "url": "/part3/chapter_4/#what-steps-should-your-organization-take",
    
    "relUrl": "/part3/chapter_4/#what-steps-should-your-organization-take"
  },"34": {
    "doc": "4 What steps should your organization take?",
    "title": "4 What steps should your organization take?",
    "content": " ",
    "url": "/part3/chapter_4/",
    
    "relUrl": "/part3/chapter_4/"
  },"35": {
    "doc": "5 Further reading",
    "title": "Further reading",
    "content": "I want to learn the technical details . For (late) high school students: . (or those who followed high-school level mathematics): . | Quantum Quest [EN] (intensive 5-week online course about theory of quantum computing. Materials freely available for self-study).  . | Quantum Rules [NL] (1-day lab experiments dealing with quantum physics) . | Masterclass Quantum [NL] (3-day extracurricular course about the theory of quantum computing and particle physics) . | . Undergraduate (Bachelor’s) university level: . | Quantum.Country [Website] – the “Duolingo of Quantum Computing”, a very well-written introduction for those with late high-school or early university level math background.  . | Quantum Computation and Quantum Information (Nielsen, Chuang) [Book] – the “bible of quantum computing”. Perhaps not the most up-to-date, but definitely the most well-known resource in our field. Sets the standards for jargon and notation.  . | . | Quantum Computer Science: An Introduction (Mermin) [Book] – a well-written introduction, with quite some focus on manipulating quantum circuits. | Quantum Computing Since Democritus (Aaronson) [Book] – Aaronson is an authority in the field. His book touched upon many topics such as the foundations of computer science, black holes and consciousness, making it a good read for those looking for something much more broad than just quantum computing. | . Graduate (Master’s) level: . These assume no prior knowledge, but require a strong background in mathematics (i.e. Linear Algebra, Calculus, advanced inequality bounds and approximations, etc.). In exchange, they go into much more detail.  . | Lecture Notes for UvA course “Quantum Computing” by Ronald de Wolf, which is frequently updated and features some cutting-edge algorithms. Via the course website, you can find the link and password to view all the recorded lectures too.  | . | Lecture Notes for Caltech course “Quantum Computing” by John Preskil  | .   . For research projects, internships or theses: . | Internships offered at Centrum Wiskunde en Informatica . | Quantum Delta NL hosts a job board.  . | Students of University of Amsterdam can find quantum projects on Datanose.   . | . Scientific papers . Introductions mostly aimed at (non-quantum) scientists. All papers we mention are open-access and peer-reviewed, which guarantees a correct and balanced presentation (and makes them suitable for you to cite).  . | Quantum algorithms: an overview (Ashley Montanaro) . | The Potential Impact of Quantum Computers on Society (Ronald de Wolf) [video lecture] . | . Scientific opinions and discussions . | Scott Aaronson’s blog. Although written from a theoretical computer science perspective, this blog addresses a very broad range of quantum computing topics. Prof. Aaronson has a strong authority in the field, and his posts attract readership and comments from a broad range of prominent scientists.  | . Scientific news . None of these focus exclusively on Quantum Technology, but all offer high-quality news (and surely none would miss any important quantum breakthroughs).  . | Quanta Magazine . | Phys.org . | Quantum Universe [NL] . | . I want to learn to program a quantum computer . There are several programming packages for quantum computers, mostly maintained by major hardware providers. Nearly all of these offer great introductory tutorials that guide your through both the basics of Quantum Computing and the usage of the package.  . The ones we recommend below are all in Python:  . | Qiskit: Introduction to Quantum Computing (by IBM) . | Cirq tutorials (by Google)  . | QWorld Bronze offers various online training programs around the world, mostly focused on Qiskit and sometimes ProjectQ. | . I want to learn more about business opportunities . Business News Websites . | The Quantum Observer – newly formed news collection platform, allowing upvotes and comments to news articles.  | . | Quantum Computing Report – don’t be fooled by the basic look on the website. The content is written with a very critical eye and with very relevant contextual information.  | . | The Quantum Insider | . Overview articles about business opportunities (close to this blog) . Of course, we first recommend that you start reading our Professional’s Guide to Quantum Computing!  . Many others have written similar guides. Most of these come from consultants of hardware providers who have a financial interest in making others get started with quantum. In our opinion, the articles are sometimes too optimistic and predict that quantum applications will come much sooner than the typical expert would anticipate. On the other hand, they collect insightful details about financial matters.  . | Deloitte – A business leader’s guide to quantum technology | . | McKinsey – A game plan for quantum computing  | . | BCG – The Next Decade in Quantum Computing—and How to Play | . Workshops . | The Workshop General Awareness Quantum Computing is an introduction to business opportunties that requires no deep mathemtical background, but gives an essential overview to how quantum computers will impact businesses and governments.  | . Major conferences . | Q2B (organized by QCWare) . | IQT (Inside Quantum Technology) . | Quantum.Tech (organized by Alpha Events)s . | . ",
    "url": "/part3/chapter_5/#further-reading",
    
    "relUrl": "/part3/chapter_5/#further-reading"
  },"36": {
    "doc": "5 Further reading",
    "title": "5 Further reading",
    "content": " ",
    "url": "/part3/chapter_5/",
    
    "relUrl": "/part3/chapter_5/"
  }
}
