<!-- ---
title: Boxes NWE
layout: default
nav_order: 100
--- -->




<details markdown="1">

<summary>asdf</summary>

To some degree, we can still greatly reduce errors by creating more
accurate hardware. However, quantum objects are so incredibly fragile
that even getting down to 10<sup>-2</sup> errors requires some of the
world’s most astonishing engineering. We definitely hope to see
two-qubit gate errors reduced to 10<sup>-3</sup> and perhaps even
10<sup>-4</sup>, but achieving targets of 10<sup>-9</sup> seems unlikely
with incremental hardware engineering alone. On the other hand, quantum
error correction is incredibly effective: the error drops dramatically
at the cost of adding a modest number of qubits, which are assumed to be
scalable anyway. That’s why experts agree that error correction is the
right way forward.  

</details>

<details markdown="1">

<summary>**Do we use error correction in classical computers too?**</summary>

This might be a good moment to appreciate the incredible perfection of
classical computer chips: while doing billions of steps per second,
running for months in a row, sometimes with thousands of cores at a
time, errors in CPUs practically never occur. I was hoping to find hard
numbers on this, but companies like Intel and AMD seem to keep this
under stringent non-disclosure agreements. However,
some [research](https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.106.176801) shows
that errors under 10<sup>-20</sup> are easily attained as long as we
don’t push processors to their limits (in terms of voltages and clock
speeds). Memory (RAM) does often come with error correction for
high-performance supercomputers, and some form of [CPU error
correction](https://en.wikipedia.org/wiki/Reliability,_availability_and_serviceability#Hardware_features) was
sometimes used in older mainframes and (even today) in [space
probes](https://arstechnica.com/science/2019/11/space-grade-cpus-how-do-you-send-more-computing-power-into-space/). 

</details>